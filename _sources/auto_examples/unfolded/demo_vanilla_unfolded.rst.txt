
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/unfolded/demo_vanilla_unfolded.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_unfolded_demo_vanilla_unfolded.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_unfolded_demo_vanilla_unfolded.py:


Vanilla Unfolded algorithm for super-resolution
====================================================================================================

This is a simple example to show how to use vanilla unfolded Plug-and-Play.
The DnCNN denoiser and the algorithm parameters (stepsize, regularization parameters) are trained jointly.
For simplicity, we show how to train the algorithm on a  small dataset. For optimal results, use a larger dataset.
For visualizing the training, you can use Weight&Bias (wandb) by setting ``wandb_vis=True``.

.. GENERATED FROM PYTHON SOURCE LINES 10-21

.. code-block:: Python


    import deepinv as dinv
    from pathlib import Path
    import torch
    from torch.utils.data import DataLoader
    from deepinv.optim.data_fidelity import L2
    from deepinv.optim.prior import PnP
    from deepinv.unfolded import unfolded_builder
    from torchvision import transforms
    from deepinv.utils.demo import load_dataset








.. GENERATED FROM PYTHON SOURCE LINES 22-25

Setup paths for data loading and results.
----------------------------------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 25-37

.. code-block:: Python


    BASE_DIR = Path(".")
    ORIGINAL_DATA_DIR = BASE_DIR / "datasets"
    DATA_DIR = BASE_DIR / "measurements"
    RESULTS_DIR = BASE_DIR / "results"
    CKPT_DIR = BASE_DIR / "ckpts"

    # Set the global random seed from pytorch to ensure reproducibility of the example.
    torch.manual_seed(0)

    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"








.. GENERATED FROM PYTHON SOURCE LINES 38-41

Load base image datasets and degradation operators.
----------------------------------------------------------------------------------------
In this example, we use the CBSD500 dataset for training and the Set3C dataset for testing.

.. GENERATED FROM PYTHON SOURCE LINES 41-46

.. code-block:: Python


    img_size = 64 if torch.cuda.is_available() else 32
    n_channels = 3  # 3 for color images, 1 for gray-scale images
    operation = "super-resolution"








.. GENERATED FROM PYTHON SOURCE LINES 47-50

Generate a dataset of low resolution images and load it.
----------------------------------------------------------------------------------------
We use the Downsampling class from the physics module to generate a dataset of low resolution images.

.. GENERATED FROM PYTHON SOURCE LINES 50-105

.. code-block:: Python


    # For simplicity, we use a small dataset for training.
    # To be replaced for optimal results. For example, you can use the larger "drunet" dataset.
    train_dataset_name = "CBSD500"
    test_dataset_name = "set3c"
    # Specify the  train and test transforms to be applied to the input images.
    test_transform = transforms.Compose(
        [transforms.CenterCrop(img_size), transforms.ToTensor()]
    )
    train_transform = transforms.Compose(
        [transforms.RandomCrop(img_size), transforms.ToTensor()]
    )
    # Define the base train and test datasets of clean images.
    train_base_dataset = load_dataset(
        train_dataset_name, ORIGINAL_DATA_DIR, transform=train_transform
    )
    test_base_dataset = load_dataset(
        test_dataset_name, ORIGINAL_DATA_DIR, transform=test_transform
    )

    # Use parallel dataloader if using a GPU to fasten training, otherwise, as all computes are on CPU, use synchronous
    # dataloading.
    num_workers = 4 if torch.cuda.is_available() else 0

    # Degradation parameters
    factor = 2
    noise_level_img = 0.03

    # Generate the gaussian blur downsampling operator.
    physics = dinv.physics.Downsampling(
        filter="gaussian",
        img_size=(n_channels, img_size, img_size),
        factor=factor,
        device=device,
        noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),
    )
    my_dataset_name = "demo_unfolded_sr"
    n_images_max = (
        1000 if torch.cuda.is_available() else 10
    )  # maximal number of images used for training
    measurement_dir = DATA_DIR / train_dataset_name / operation
    generated_datasets_path = dinv.datasets.generate_dataset(
        train_dataset=train_base_dataset,
        test_dataset=test_base_dataset,
        physics=physics,
        device=device,
        save_dir=measurement_dir,
        train_datapoints=n_images_max,
        num_workers=num_workers,
        dataset_filename=str(my_dataset_name),
    )

    train_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)
    test_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading datasets/CBSD500.zip
      0%|          | 0.00/71.0M [00:00<?, ?iB/s]      0%|          | 327k/71.0M [00:00<00:22, 3.14MiB/s]      1%|          | 687k/71.0M [00:00<00:20, 3.38MiB/s]      1%|▏         | 1.03M/71.0M [00:00<00:21, 3.23MiB/s]      2%|▏         | 1.36M/71.0M [00:00<00:21, 3.23MiB/s]      2%|▏         | 1.68M/71.0M [00:00<00:21, 3.22MiB/s]      3%|▎         | 2.01M/71.0M [00:00<00:21, 3.15MiB/s]      3%|▎         | 2.37M/71.0M [00:00<00:20, 3.27MiB/s]      4%|▍         | 2.75M/71.0M [00:00<00:19, 3.42MiB/s]      4%|▍         | 3.16M/71.0M [00:00<00:18, 3.63MiB/s]      5%|▌         | 3.57M/71.0M [00:01<00:17, 3.76MiB/s]      6%|▌         | 4.00M/71.0M [00:01<00:17, 3.89MiB/s]      6%|▋         | 4.46M/71.0M [00:01<00:16, 4.07MiB/s]      7%|▋         | 4.88M/71.0M [00:01<00:16, 4.08MiB/s]      7%|▋         | 5.29M/71.0M [00:01<00:16, 3.95MiB/s]      8%|▊         | 5.69M/71.0M [00:01<00:17, 3.67MiB/s]      9%|▊         | 6.06M/71.0M [00:01<00:17, 3.65MiB/s]      9%|▉         | 6.43M/71.0M [00:01<00:17, 3.59MiB/s]     10%|▉         | 6.79M/71.0M [00:01<00:18, 3.47MiB/s]     10%|█         | 7.14M/71.0M [00:02<00:18, 3.41MiB/s]     11%|█         | 7.49M/71.0M [00:02<00:18, 3.41MiB/s]     11%|█         | 7.86M/71.0M [00:02<00:18, 3.48MiB/s]     12%|█▏        | 8.26M/71.0M [00:02<00:17, 3.58MiB/s]     12%|█▏        | 8.63M/71.0M [00:02<00:17, 3.62MiB/s]     13%|█▎        | 9.00M/71.0M [00:02<00:17, 3.50MiB/s]     13%|█▎        | 9.44M/71.0M [00:02<00:16, 3.73MiB/s]     14%|█▍        | 9.81M/71.0M [00:02<00:16, 3.70MiB/s]     14%|█▍        | 10.2M/71.0M [00:02<00:17, 3.55MiB/s]     15%|█▍        | 10.5M/71.0M [00:02<00:17, 3.54MiB/s]     15%|█▌        | 10.9M/71.0M [00:03<00:16, 3.57MiB/s]     16%|█▌        | 11.3M/71.0M [00:03<00:16, 3.55MiB/s]     16%|█▋        | 11.7M/71.0M [00:03<00:16, 3.67MiB/s]     17%|█▋        | 12.1M/71.0M [00:03<00:16, 3.65MiB/s]     18%|█▊        | 12.4M/71.0M [00:03<00:16, 3.62MiB/s]     18%|█▊        | 12.8M/71.0M [00:03<00:16, 3.53MiB/s]     19%|█▊        | 13.2M/71.0M [00:03<00:16, 3.59MiB/s]     19%|█▉        | 13.6M/71.0M [00:03<00:15, 3.64MiB/s]     20%|█▉        | 14.0M/71.0M [00:03<00:15, 3.79MiB/s]     20%|██        | 14.4M/71.0M [00:03<00:14, 3.79MiB/s]     21%|██        | 14.8M/71.0M [00:04<00:15, 3.64MiB/s]     21%|██▏       | 15.1M/71.0M [00:04<00:15, 3.58MiB/s]     22%|██▏       | 15.5M/71.0M [00:04<00:15, 3.65MiB/s]     22%|██▏       | 15.9M/71.0M [00:04<00:14, 3.73MiB/s]     23%|██▎       | 16.3M/71.0M [00:04<00:14, 3.73MiB/s]     23%|██▎       | 16.7M/71.0M [00:04<00:14, 3.71MiB/s]     24%|██▍       | 17.0M/71.0M [00:04<00:14, 3.61MiB/s]     25%|██▍       | 17.4M/71.0M [00:04<00:14, 3.66MiB/s]     25%|██▌       | 17.8M/71.0M [00:04<00:14, 3.62MiB/s]     26%|██▌       | 18.2M/71.0M [00:05<00:14, 3.67MiB/s]     26%|██▌       | 18.5M/71.0M [00:05<00:14, 3.64MiB/s]     27%|██▋       | 18.9M/71.0M [00:05<00:14, 3.51MiB/s]     27%|██▋       | 19.3M/71.0M [00:05<00:14, 3.59MiB/s]     28%|██▊       | 19.6M/71.0M [00:05<00:14, 3.45MiB/s]     28%|██▊       | 20.0M/71.0M [00:05<00:14, 3.46MiB/s]     29%|██▊       | 20.4M/71.0M [00:05<00:14, 3.41MiB/s]     29%|██▉       | 20.7M/71.0M [00:05<00:15, 3.35MiB/s]     30%|██▉       | 21.1M/71.0M [00:05<00:14, 3.39MiB/s]     30%|███       | 21.4M/71.0M [00:05<00:14, 3.44MiB/s]     31%|███       | 21.8M/71.0M [00:06<00:14, 3.46MiB/s]     31%|███       | 22.2M/71.0M [00:06<00:13, 3.51MiB/s]     32%|███▏      | 22.5M/71.0M [00:06<00:13, 3.51MiB/s]     32%|███▏      | 22.9M/71.0M [00:06<00:13, 3.51MiB/s]     33%|███▎      | 23.2M/71.0M [00:06<00:13, 3.45MiB/s]     33%|███▎      | 23.6M/71.0M [00:06<00:13, 3.43MiB/s]     34%|███▎      | 23.9M/71.0M [00:06<00:14, 3.32MiB/s]     34%|███▍      | 24.2M/71.0M [00:06<00:14, 3.23MiB/s]     35%|███▍      | 24.6M/71.0M [00:06<00:13, 3.34MiB/s]     35%|███▌      | 24.9M/71.0M [00:07<00:13, 3.34MiB/s]     36%|███▌      | 25.3M/71.0M [00:07<00:13, 3.33MiB/s]     36%|███▌      | 25.6M/71.0M [00:07<00:13, 3.28MiB/s]     37%|███▋      | 26.0M/71.0M [00:07<00:13, 3.32MiB/s]     37%|███▋      | 26.3M/71.0M [00:07<00:13, 3.40MiB/s]     38%|███▊      | 26.7M/71.0M [00:07<00:13, 3.38MiB/s]     38%|███▊      | 27.0M/71.0M [00:07<00:12, 3.41MiB/s]     39%|███▊      | 27.3M/71.0M [00:07<00:12, 3.36MiB/s]     39%|███▉      | 27.7M/71.0M [00:07<00:12, 3.35MiB/s]     40%|███▉      | 28.1M/71.0M [00:07<00:12, 3.46MiB/s]     40%|████      | 28.4M/71.0M [00:08<00:11, 3.56MiB/s]     41%|████      | 28.8M/71.0M [00:08<00:11, 3.56MiB/s]     41%|████      | 29.2M/71.0M [00:08<00:11, 3.62MiB/s]     42%|████▏     | 29.5M/71.0M [00:08<00:11, 3.55MiB/s]     42%|████▏     | 29.9M/71.0M [00:08<00:11, 3.55MiB/s]     43%|████▎     | 30.3M/71.0M [00:08<00:11, 3.55MiB/s]     43%|████▎     | 30.6M/71.0M [00:08<00:11, 3.46MiB/s]     44%|████▎     | 31.0M/71.0M [00:08<00:11, 3.38MiB/s]     44%|████▍     | 31.3M/71.0M [00:08<00:11, 3.33MiB/s]     45%|████▍     | 31.7M/71.0M [00:08<00:11, 3.32MiB/s]     45%|████▌     | 32.0M/71.0M [00:09<00:11, 3.42MiB/s]     46%|████▌     | 32.4M/71.0M [00:09<00:11, 3.46MiB/s]     46%|████▌     | 32.8M/71.0M [00:09<00:11, 3.46MiB/s]     47%|████▋     | 33.1M/71.0M [00:09<00:10, 3.47MiB/s]     47%|████▋     | 33.5M/71.0M [00:09<00:11, 3.40MiB/s]     48%|████▊     | 33.8M/71.0M [00:09<00:10, 3.41MiB/s]     48%|████▊     | 34.2M/71.0M [00:09<00:10, 3.43MiB/s]     49%|████▊     | 34.6M/71.0M [00:09<00:10, 3.50MiB/s]     49%|████▉     | 35.0M/71.0M [00:09<00:09, 3.61MiB/s]     50%|████▉     | 35.4M/71.0M [00:10<00:09, 3.67MiB/s]     50%|█████     | 35.8M/71.0M [00:10<00:09, 3.75MiB/s]     51%|█████     | 36.2M/71.0M [00:10<00:09, 3.82MiB/s]     52%|█████▏    | 36.6M/71.0M [00:10<00:08, 3.89MiB/s]     52%|█████▏    | 37.0M/71.0M [00:10<00:08, 3.94MiB/s]     53%|█████▎    | 37.4M/71.0M [00:10<00:08, 3.96MiB/s]     53%|█████▎    | 37.8M/71.0M [00:10<00:08, 3.90MiB/s]     54%|█████▍    | 38.2M/71.0M [00:10<00:08, 3.94MiB/s]     54%|█████▍    | 38.6M/71.0M [00:10<00:08, 3.76MiB/s]     55%|█████▍    | 39.0M/71.0M [00:10<00:08, 3.72MiB/s]     55%|█████▌    | 39.4M/71.0M [00:11<00:08, 3.69MiB/s]     56%|█████▌    | 39.7M/71.0M [00:11<00:08, 3.69MiB/s]     57%|█████▋    | 40.1M/71.0M [00:11<00:08, 3.68MiB/s]     57%|█████▋    | 40.5M/71.0M [00:11<00:08, 3.66MiB/s]     58%|█████▊    | 40.8M/71.0M [00:11<00:08, 3.66MiB/s]     58%|█████▊    | 41.2M/71.0M [00:11<00:08, 3.71MiB/s]     59%|█████▊    | 41.6M/71.0M [00:11<00:07, 3.74MiB/s]     59%|█████▉    | 42.0M/71.0M [00:11<00:07, 3.73MiB/s]     60%|█████▉    | 42.4M/71.0M [00:11<00:07, 3.79MiB/s]     60%|██████    | 42.8M/71.0M [00:11<00:07, 3.78MiB/s]     61%|██████    | 43.2M/71.0M [00:12<00:07, 3.79MiB/s]     61%|██████▏   | 43.6M/71.0M [00:12<00:07, 3.87MiB/s]     62%|██████▏   | 44.0M/71.0M [00:12<00:07, 3.79MiB/s]     62%|██████▏   | 44.3M/71.0M [00:12<00:07, 3.76MiB/s]     63%|██████▎   | 44.7M/71.0M [00:12<00:07, 3.71MiB/s]     64%|██████▎   | 45.1M/71.0M [00:12<00:07, 3.55MiB/s]     64%|██████▍   | 45.5M/71.0M [00:12<00:07, 3.63MiB/s]     65%|██████▍   | 45.9M/71.0M [00:12<00:06, 3.71MiB/s]     65%|██████▌   | 46.3M/71.0M [00:12<00:06, 3.75MiB/s]     66%|██████▌   | 46.6M/71.0M [00:13<00:06, 3.75MiB/s]     66%|██████▋   | 47.0M/71.0M [00:13<00:06, 3.78MiB/s]     67%|██████▋   | 47.4M/71.0M [00:13<00:06, 3.78MiB/s]     67%|██████▋   | 47.8M/71.0M [00:13<00:06, 3.79MiB/s]     68%|██████▊   | 48.2M/71.0M [00:13<00:05, 3.87MiB/s]     68%|██████▊   | 48.6M/71.0M [00:13<00:06, 3.68MiB/s]     69%|██████▉   | 49.0M/71.0M [00:13<00:06, 3.63MiB/s]     70%|██████▉   | 49.3M/71.0M [00:13<00:05, 3.69MiB/s]     70%|███████   | 49.8M/71.0M [00:13<00:05, 3.77MiB/s]     71%|███████   | 50.1M/71.0M [00:13<00:05, 3.72MiB/s]     71%|███████   | 50.5M/71.0M [00:14<00:05, 3.74MiB/s]     72%|███████▏  | 50.9M/71.0M [00:14<00:05, 3.65MiB/s]     72%|███████▏  | 51.3M/71.0M [00:14<00:05, 3.66MiB/s]     73%|███████▎  | 51.7M/71.0M [00:14<00:05, 3.67MiB/s]     73%|███████▎  | 52.1M/71.0M [00:14<00:05, 3.77MiB/s]     74%|███████▍  | 52.4M/71.0M [00:14<00:04, 3.77MiB/s]     74%|███████▍  | 52.9M/71.0M [00:14<00:04, 3.86MiB/s]     75%|███████▌  | 53.3M/71.0M [00:14<00:04, 3.91MiB/s]     76%|███████▌  | 53.7M/71.0M [00:14<00:04, 3.95MiB/s]     76%|███████▌  | 54.1M/71.0M [00:14<00:04, 4.01MiB/s]     77%|███████▋  | 54.5M/71.0M [00:15<00:04, 4.05MiB/s]     77%|███████▋  | 54.9M/71.0M [00:15<00:03, 4.04MiB/s]     78%|███████▊  | 55.4M/71.0M [00:15<00:03, 4.08MiB/s]     79%|███████▊  | 55.8M/71.0M [00:15<00:03, 4.05MiB/s]     79%|███████▉  | 56.2M/71.0M [00:15<00:03, 4.02MiB/s]     80%|███████▉  | 56.6M/71.0M [00:15<00:03, 3.96MiB/s]     80%|████████  | 57.0M/71.0M [00:15<00:03, 3.66MiB/s]     81%|████████  | 57.3M/71.0M [00:15<00:03, 3.67MiB/s]     81%|████████▏ | 57.7M/71.0M [00:15<00:03, 3.65MiB/s]     82%|████████▏ | 58.1M/71.0M [00:16<00:03, 3.66MiB/s]     82%|████████▏ | 58.5M/71.0M [00:16<00:03, 3.69MiB/s]     83%|████████▎ | 58.8M/71.0M [00:16<00:03, 3.64MiB/s]     83%|████████▎ | 59.2M/71.0M [00:16<00:03, 3.58MiB/s]     84%|████████▍ | 59.6M/71.0M [00:16<00:03, 3.64MiB/s]     85%|████████▍ | 60.0M/71.0M [00:16<00:02, 3.67MiB/s]     85%|████████▌ | 60.4M/71.0M [00:16<00:02, 3.62MiB/s]     86%|████████▌ | 60.7M/71.0M [00:16<00:02, 3.70MiB/s]     86%|████████▌ | 61.2M/71.0M [00:16<00:02, 3.82MiB/s]     87%|████████▋ | 61.6M/71.0M [00:16<00:02, 3.83MiB/s]     87%|████████▋ | 61.9M/71.0M [00:17<00:02, 3.74MiB/s]     88%|████████▊ | 62.3M/71.0M [00:17<00:02, 3.65MiB/s]     88%|████████▊ | 62.7M/71.0M [00:17<00:02, 3.69MiB/s]     89%|████████▉ | 63.1M/71.0M [00:17<00:02, 3.73MiB/s]     89%|████████▉ | 63.5M/71.0M [00:17<00:01, 3.81MiB/s]     90%|█████████ | 63.9M/71.0M [00:17<00:01, 3.86MiB/s]     91%|█████████ | 64.3M/71.0M [00:17<00:01, 3.95MiB/s]     91%|█████████ | 64.7M/71.0M [00:17<00:01, 3.94MiB/s]     92%|█████████▏| 65.1M/71.0M [00:17<00:01, 3.63MiB/s]     92%|█████████▏| 65.5M/71.0M [00:18<00:01, 3.57MiB/s]     93%|█████████▎| 65.9M/71.0M [00:18<00:01, 3.57MiB/s]     93%|█████████▎| 66.3M/71.0M [00:18<00:01, 3.76MiB/s]     94%|█████████▍| 66.7M/71.0M [00:18<00:01, 3.78MiB/s]     95%|█████████▍| 67.1M/71.0M [00:18<00:01, 3.67MiB/s]     95%|█████████▌| 67.5M/71.0M [00:18<00:00, 3.60MiB/s]     96%|█████████▌| 67.8M/71.0M [00:18<00:00, 3.58MiB/s]     96%|█████████▌| 68.2M/71.0M [00:18<00:00, 3.58MiB/s]     97%|█████████▋| 68.6M/71.0M [00:18<00:00, 3.75MiB/s]     97%|█████████▋| 69.1M/71.0M [00:18<00:00, 3.94MiB/s]     98%|█████████▊| 69.5M/71.0M [00:19<00:00, 4.03MiB/s]     98%|█████████▊| 69.9M/71.0M [00:19<00:00, 4.03MiB/s]     99%|█████████▉| 70.3M/71.0M [00:19<00:00, 4.05MiB/s]    100%|█████████▉| 70.7M/71.0M [00:19<00:00, 4.05MiB/s]    100%|██████████| 71.0M/71.0M [00:19<00:00, 3.65MiB/s]
    CBSD500 dataset downloaded in datasets
    Downloading datasets/set3c.zip
      0%|          | 0.00/385k [00:00<?, ?iB/s]    100%|██████████| 385k/385k [00:00<00:00, 26.5MiB/s]
    set3c dataset downloaded in datasets
    Dataset has been saved in measurements/CBSD500/super-resolution




.. GENERATED FROM PYTHON SOURCE LINES 106-113

Define the unfolded PnP algorithm.
----------------------------------------------------------------------------------------
We use the helper function :meth:`deepinv.unfolded.unfolded_builder` to defined the Unfolded architecture.
The chosen algorithm is here DRS (Douglas-Rachford Splitting).
Note that if the prior (resp. a parameter) is initialized with a list of lenght max_iter,
then a distinct model (resp. parameter) is trained for each iteration.
For fixed trained model prior (resp. parameter) across iterations, initialize with a single element.

.. GENERATED FROM PYTHON SOURCE LINES 113-153

.. code-block:: Python


    # Unrolled optimization algorithm parameters
    max_iter = 5  # number of unfolded layers

    # Select the data fidelity term
    data_fidelity = L2()

    # Set up the trainable denoising prior
    # Here the prior model is common for all iterations
    prior = PnP(denoiser=dinv.models.DnCNN(depth=7, pretrained=None).to(device))

    # The parameters are initialized with a list of length max_iter, so that a distinct parameter is trained for each iteration.
    stepsize = [1] * max_iter  # stepsize of the algorithm
    sigma_denoiser = [0.01] * max_iter  # noise level parameter of the denoiser
    beta = 1  # relaxation parameter of the Douglas-Rachford splitting
    params_algo = {  # wrap all the restoration parameters in a 'params_algo' dictionary
        "stepsize": stepsize,
        "g_param": sigma_denoiser,
        "beta": beta,
    }
    trainable_params = [
        "g_param",
        "stepsize",
        "beta",
    ]  # define which parameters from 'params_algo' are trainable

    # Logging parameters
    verbose = True
    wandb_vis = False  # plot curves and images in Weight&Bias

    # Define the unfolded trainable model.
    model = unfolded_builder(
        iteration="DRS",
        params_algo=params_algo.copy(),
        trainable_params=trainable_params,
        data_fidelity=data_fidelity,
        max_iter=max_iter,
        prior=prior,
    )








.. GENERATED FROM PYTHON SOURCE LINES 154-157

Define the training parameters.
----------------------------------------------------------------------------------------
We use the Adam optimizer and the StepLR scheduler.

.. GENERATED FROM PYTHON SOURCE LINES 157-179

.. code-block:: Python



    # training parameters
    epochs = 10 if torch.cuda.is_available() else 2
    learning_rate = 5e-4
    train_batch_size = 32 if torch.cuda.is_available() else 1
    test_batch_size = 3

    # choose optimizer and scheduler
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8))

    # choose supervised training loss
    losses = [dinv.loss.SupLoss(metric=dinv.metric.MSE())]

    train_dataloader = DataLoader(
        train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True
    )
    test_dataloader = DataLoader(
        test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False
    )








.. GENERATED FROM PYTHON SOURCE LINES 180-183

Train the network
----------------------------------------------------------------------------------------
We train the network using the :meth:`deepinv.Trainer` class.

.. GENERATED FROM PYTHON SOURCE LINES 183-203

.. code-block:: Python


    trainer = dinv.Trainer(
        model,
        physics=physics,
        train_dataloader=train_dataloader,
        eval_dataloader=test_dataloader,
        epochs=epochs,
        scheduler=scheduler,
        losses=losses,
        optimizer=optimizer,
        device=device,
        save_path=str(CKPT_DIR / operation),
        verbose=verbose,
        show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.
        wandb_vis=wandb_vis,  # training visualization can be done in Weight&Bias
    )

    model = trainer.train()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The model has 188174 trainable parameters
    Train epoch 0: TotalLoss=140.864, PSNR=-0.094
    Eval epoch 0: PSNR=2.717
    Train epoch 1: TotalLoss=0.276, PSNR=6.355
    Eval epoch 1: PSNR=3.146




.. GENERATED FROM PYTHON SOURCE LINES 204-208

Test the network
--------------------------------------------



.. GENERATED FROM PYTHON SOURCE LINES 208-228

.. code-block:: Python

    trainer.test(test_dataloader)

    test_sample, _ = next(iter(test_dataloader))
    model.eval()
    test_sample = test_sample.to(device)

    # Get the measurements and the ground truth
    y = physics(test_sample)
    with torch.no_grad():
        rec = model(y, physics=physics)

    backprojected = physics.A_adjoint(y)

    dinv.utils.plot(
        [backprojected, rec, test_sample],
        titles=["Linear", "Reconstruction", "Ground truth"],
        suptitle="Reconstruction results",
    )





.. image-sg:: /auto_examples/unfolded/images/sphx_glr_demo_vanilla_unfolded_001.png
   :alt: Reconstruction results, Linear, Reconstruction, Ground truth
   :srcset: /auto_examples/unfolded/images/sphx_glr_demo_vanilla_unfolded_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Eval epoch 0: PSNR=3.146, PSNR no learning=5.996
    Test results:
    PSNR no learning: 5.996 +- 1.188
    PSNR: 3.146 +- 1.309




.. GENERATED FROM PYTHON SOURCE LINES 229-235

Plotting the weights of the network.
------------------------------------

We now plot the weights of the network that were learned and check that they are different from their initialization
values. Note that ``g_param`` corresponds to :math:`\lambda` in the proximal gradient algorithm.


.. GENERATED FROM PYTHON SOURCE LINES 235-239

.. code-block:: Python


    dinv.utils.plotting.plot_parameters(
        model, init_params=params_algo, save_dir=RESULTS_DIR / "unfolded_pgd" / operation
    )



.. image-sg:: /auto_examples/unfolded/images/sphx_glr_demo_vanilla_unfolded_002.png
   :alt: demo vanilla unfolded
   :srcset: /auto_examples/unfolded/images/sphx_glr_demo_vanilla_unfolded_002.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 21.890 seconds)


.. _sphx_glr_download_auto_examples_unfolded_demo_vanilla_unfolded.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_vanilla_unfolded.ipynb <demo_vanilla_unfolded.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_vanilla_unfolded.py <demo_vanilla_unfolded.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: demo_vanilla_unfolded.zip <demo_vanilla_unfolded.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
