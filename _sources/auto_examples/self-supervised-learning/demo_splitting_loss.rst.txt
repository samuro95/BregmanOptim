
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/self-supervised-learning/demo_splitting_loss.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_self-supervised-learning_demo_splitting_loss.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_self-supervised-learning_demo_splitting_loss.py:


Self-supervised learning with measurement splitting
===================================================

We demonstrate self-supervised learning with measurement splitting, to
train a denoiser network on the MNIST dataset. The physics here is noisy
computed tomography, as is the case in
`Noise2Inverse <https://arxiv.org/abs/2001.11801>`__. Note this example
can also be easily applied to undersampled multicoil MRI as is the case
in `SSDU <https://pubmed.ncbi.nlm.nih.gov/32614100/>`__.

Measurement splitting constructs a ground-truth free loss
:math:`\frac{m}{m_2}\| y_2 - A_2 \inversef{y_1}{A_1}\|^2` by splitting
the measurement and the forward operator using a randomly generated
mask.

See :class:`deepinv.loss.SplittingLoss` for full details.

.. GENERATED FROM PYTHON SOURCE LINES 20-31

.. code-block:: Python


    import deepinv as dinv
    from torch.utils.data import DataLoader
    import torch
    from torchvision import transforms, datasets
    from deepinv.models.utils import get_weights_url

    torch.manual_seed(0)
    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"









.. GENERATED FROM PYTHON SOURCE LINES 32-55

Define loss
~~~~~~~~~~~

Our implementation has multiple optional parameters that control how the
splitting is to be achieved. For example, you can:

-  Use ``split_ratio`` to set the ratio of pixels used in the forward
   pass vs the loss;
-  Define custom masking methods using a ``mask_generator`` such as
   :class:`deepinv.physics.generator.BernoulliSplittingMaskGenerator`
   or :class:`deepinv.physics.generator.GaussianSplittingMaskGenerator`;
-  Use ``eval_n_samples`` to set how many realisations of the random
   mask is used at evaluation time;
-  Optionally disable measurement splitting at evaluation time using
   ``eval_split_input`` (as is the case in
   `SSDU <https://pubmed.ncbi.nlm.nih.gov/32614100/>`__).
-  Average over both input and output masks at evaluation time using
   ``eval_split_output``. See :class:`deepinv.loss.SplittingLoss` for
   details.

Note that after the model has been defined, the loss must also "adapt"
the model.


.. GENERATED FROM PYTHON SOURCE LINES 55-59

.. code-block:: Python


    loss = dinv.loss.SplittingLoss(split_ratio=0.6, eval_split_input=True, eval_n_samples=5)









.. GENERATED FROM PYTHON SOURCE LINES 60-72

Prepare data
~~~~~~~~~~~~

We use the ``torchvision`` MNIST dataset, and use noisy tomography
physics (with number of angles equal to the image size) for the forward
operator.

.. note::

     We use a subset of the whole training set to reduce the computational load of the example.
     We recommend to use the whole set by setting ``train_datapoints=test_datapoints=None`` to get the best results.


.. GENERATED FROM PYTHON SOURCE LINES 72-102

.. code-block:: Python


    transform = transforms.Compose([transforms.ToTensor()])

    train_dataset = datasets.MNIST(root=".", train=True, transform=transform, download=True)
    test_dataset = datasets.MNIST(root=".", train=False, transform=transform, download=True)

    physics = dinv.physics.Tomography(
        angles=28,
        img_width=28,
        noise_model=dinv.physics.noise.GaussianNoise(0.1),
        device=device,
    )

    deepinv_datasets_path = dinv.datasets.generate_dataset(
        train_dataset=train_dataset,
        test_dataset=test_dataset,
        physics=physics,
        device=device,
        save_dir="MNIST",
        train_datapoints=100,
        test_datapoints=10,
    )

    train_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)
    test_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)

    train_dataloader = DataLoader(train_dataset, shuffle=True)
    test_dataloader = DataLoader(test_dataset, shuffle=False)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
    Failed to download (trying next):
    HTTP Error 403: Forbidden

    Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz
    Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz
      0%|          | 0.00/9.91M [00:00<?, ?B/s]     44%|████▍     | 4.36M/9.91M [00:00<00:00, 43.5MB/s]    100%|██████████| 9.91M/9.91M [00:00<00:00, 66.2MB/s]
    Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw

    Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
    Failed to download (trying next):
    HTTP Error 403: Forbidden

    Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz
    Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz
      0%|          | 0.00/28.9k [00:00<?, ?B/s]    100%|██████████| 28.9k/28.9k [00:00<00:00, 13.9MB/s]
    Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw

    Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
    Failed to download (trying next):
    HTTP Error 403: Forbidden

    Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz
    Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz
      0%|          | 0.00/1.65M [00:00<?, ?B/s]    100%|██████████| 1.65M/1.65M [00:00<00:00, 65.5MB/s]
    Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw

    Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
    Failed to download (trying next):
    HTTP Error 403: Forbidden

    Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz
    Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz
      0%|          | 0.00/4.54k [00:00<?, ?B/s]    100%|██████████| 4.54k/4.54k [00:00<00:00, 23.8MB/s]
    Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw

    Dataset has been saved in MNIST




.. GENERATED FROM PYTHON SOURCE LINES 103-117

Define model
~~~~~~~~~~~~

We use a simple U-Net architecture with 2 scales as the denoiser
network.

To reduce training time, we use a pretrained model. Here we demonstrate
training with 100 images for 1 epoch, after having loaded a pretrained
model trained that was with 1000 images for 20 epochs.

.. note::

     When using the splitting loss, the model must be "adapted" by the loss, as its forward pass takes only a subset of the pixels, not the full image.


.. GENERATED FROM PYTHON SOURCE LINES 117-136

.. code-block:: Python


    model = dinv.models.ArtifactRemoval(
        dinv.models.UNet(in_channels=1, out_channels=1, scales=2).to(device), pinv=True
    )
    model = loss.adapt_model(model)

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-8)

    # Load pretrained model
    file_name = "demo_measplit_mnist_tomography.pth"
    url = get_weights_url(model_name="measplit", file_name=file_name)
    ckpt = torch.hub.load_state_dict_from_url(
        url, map_location=lambda storage, loc: storage, file_name=file_name
    )

    model.load_state_dict(ckpt["state_dict"])
    optimizer.load_state_dict(ckpt["optimizer"])






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://huggingface.co/deepinv/measplit/resolve/main/demo_measplit_mnist_tomography.pth?download=true" to /home/runner/.cache/torch/hub/checkpoints/demo_measplit_mnist_tomography.pth
      0%|          | 0.00/5.13M [00:00<?, ?B/s]     27%|██▋       | 1.38M/5.13M [00:00<00:00, 14.2MB/s]     83%|████████▎ | 4.25M/5.13M [00:00<00:00, 17.8MB/s]    100%|██████████| 5.13M/5.13M [00:00<00:00, 20.0MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 137-140

Train and test network
----------------------


.. GENERATED FROM PYTHON SOURCE LINES 140-159

.. code-block:: Python


    trainer = dinv.Trainer(
        model=model,
        physics=physics,
        epochs=1,
        losses=loss,
        optimizer=optimizer,
        device=device,
        train_dataloader=train_dataloader,
        plot_images=False,
        save_path=None,
        verbose=True,
        show_progress_bar=False,
        no_learning_method="A_dagger",  # use pseudo-inverse as no-learning baseline
    )

    model = trainer.train()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The model has 444737 trainable parameters
    Train epoch 0: TotalLoss=0.032, PSNR=29.007




.. GENERATED FROM PYTHON SOURCE LINES 160-164

Test and visualise the model outputs using a small test set. We set the
output to average over 5 iterations of random mask realisations. The
trained model improves on the no-learning reconstruction by ~7dB.


.. GENERATED FROM PYTHON SOURCE LINES 164-169

.. code-block:: Python


    trainer.plot_images = True
    trainer.test(test_dataloader)





.. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_001.png
   :alt: Ground truth, No learning, Reconstruction
   :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Eval epoch 0: PSNR=31.238, PSNR no learning=24.549
    Test results:
    PSNR no learning: 24.549 +- 1.052
    PSNR: 31.238 +- 2.738

    {'PSNR no learning': np.float64(24.548789978027344), 'PSNR no learning_std': np.float64(1.0523070216572739), 'PSNR': np.float64(31.23841247558594), 'PSNR_std': np.float64(2.73807144244024)}



.. GENERATED FROM PYTHON SOURCE LINES 170-174

Demonstrate the effect of not averaging over multiple realisations of
the splitting mask at evaluation time, by setting ``eval_n_samples=1``.
We have a worse performance:


.. GENERATED FROM PYTHON SOURCE LINES 174-179

.. code-block:: Python


    model.eval_n_samples = 1
    trainer.test(test_dataloader)





.. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_002.png
   :alt: Ground truth, No learning, Reconstruction
   :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Eval epoch 0: PSNR=29.202, PSNR no learning=24.549
    Test results:
    PSNR no learning: 24.549 +- 1.052
    PSNR: 29.202 +- 2.439

    {'PSNR no learning': np.float64(24.548789978027344), 'PSNR no learning_std': np.float64(1.0523070216572739), 'PSNR': np.float64(29.20185546875), 'PSNR_std': np.float64(2.4385367335731565)}



.. GENERATED FROM PYTHON SOURCE LINES 180-185

Furthermore, we can disable measurement splitting at evaluation
altogether by setting ``eval_split_input`` to False (this is done in
`SSDU <https://pubmed.ncbi.nlm.nih.gov/32614100/>`__). This generally is
worse than MC averaging:


.. GENERATED FROM PYTHON SOURCE LINES 185-188

.. code-block:: Python


    model.eval_split_input = False
    trainer.test(test_dataloader)



.. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_003.png
   :alt: Ground truth, No learning, Reconstruction
   :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Eval epoch 0: PSNR=31.056, PSNR no learning=24.549
    Test results:
    PSNR no learning: 24.549 +- 1.052
    PSNR: 31.056 +- 2.507

    {'PSNR no learning': np.float64(24.548789978027344), 'PSNR no learning_std': np.float64(1.0523070216572739), 'PSNR': np.float64(31.055923461914062), 'PSNR_std': np.float64(2.5073385957994816)}




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 9.833 seconds)


.. _sphx_glr_download_auto_examples_self-supervised-learning_demo_splitting_loss.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_splitting_loss.ipynb <demo_splitting_loss.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_splitting_loss.py <demo_splitting_loss.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: demo_splitting_loss.zip <demo_splitting_loss.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
