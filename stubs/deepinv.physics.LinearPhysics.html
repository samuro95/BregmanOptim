

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>LinearPhysics &mdash; deepinverse 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
    <link rel="shortcut icon" href="../_static/logo.ico"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=2709fde1"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=35a8b989"></script>
      <script>window.MathJax = {"tex": {"equationNumbers": {"autoNumber": "AMS", "useLabelIds": true}, "macros": {"forw": ["{A\\left({#1}\\right)}", 1], "noise": ["{N\\left({#1}\\right)}", 1], "inverse": ["{R\\left({#1}\\right)}", 1], "inversef": ["{R\\left({#1},{#2}\\right)}", 2], "reg": ["{g_\\sigma\\left({#1}\\right)}", 1], "regname": "g_\\sigma", "sensor": ["{\\eta\\left({#1}\\right)}", 1], "datafid": ["{f\\left({#1},{#2}\\right)}", 2], "datafidname": "f", "distance": ["{d\\left({#1},{#2}\\right)}", 2], "distancename": "d", "denoiser": ["{\\operatorname{D}_{{#2}}\\left({#1}\\right)}", 2], "denoisername": "\\operatorname{D}_{\\sigma}", "xset": "\\mathcal{X}", "yset": "\\mathcal{Y}", "group": "\\mathcal{G}", "metric": ["{d\\left({#1},{#2}\\right)}", 2], "loss": ["{\\mathcal\\left({#1}\\right)}", 1], "conj": ["{\\overline{#1}^{\\top}}", 1]}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DecomposablePhysics" href="deepinv.physics.DecomposablePhysics.html" />
    <link rel="prev" title="Physics" href="deepinv.physics.Physics.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../index.html">
            
              <img src="../_static/deepinv_logolarge.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../deepinv.physics.html">Physics</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../deepinv.physics.html#introduction">Introduction</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="deepinv.physics.Physics.html">Physics</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../deepinv.physics.html#linear-operators">Linear operators</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">LinearPhysics</a></li>
<li class="toctree-l4"><a class="reference internal" href="deepinv.physics.DecomposablePhysics.html">DecomposablePhysics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../deepinv.physics.html#parameter-dependent-operators">Parameter-dependent operators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../deepinv.physics.html#physics-generators">Physics Generators</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../deepinv.physics.html#forward-operators">Forward operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deepinv.physics.html#noise-distributions">Noise distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deepinv.physics.html#defining-new-operators">Defining new operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deepinv.physics.html#functional">Functional</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.loss.html">Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.metric.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.transform.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.denoisers.html">Denoisers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.optim.html">Optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.iterative.html">Iterative Reconstruction (PnP, RED, etc.)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.unfolded.html">Unfolded Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.sampling.html">Diffusion Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.other_models.html">Other Reconstruction Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.multigpu.html">Using multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.notation.html">Math Notation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.contributing.html">How to Contribute</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">deepinverse</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../deepinv.physics.html">Physics</a></li>
      <li class="breadcrumb-item active">LinearPhysics</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/stubs/deepinv.physics.LinearPhysics.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="linearphysics">
<h1>LinearPhysics<a class="headerlink" href="#linearphysics" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="deepinv.physics.LinearPhysics">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepinv.physics.</span></span><span class="sig-name descname"><span class="pre">LinearPhysics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A=&lt;function</span> <span class="pre">LinearPhysics.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">A_adjoint=&lt;function</span> <span class="pre">LinearPhysics.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_model=&lt;function</span> <span class="pre">LinearPhysics.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sensor_model=&lt;function</span> <span class="pre">LinearPhysics.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter=50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol=0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/physics/forward.html#LinearPhysics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.physics.LinearPhysics" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="deepinv.physics.Physics.html#deepinv.physics.Physics" title="deepinv.physics.forward.Physics"><code class="xref py py-class docutils literal notranslate"><span class="pre">Physics</span></code></a></p>
<p>Parent class for linear operators.</p>
<p>It describes the linear forward measurement process of the form</p>
<div class="math notranslate nohighlight">
\[y = N(A(x))\]</div>
<p>where <span class="math notranslate nohighlight">\(x\)</span> is an image of <span class="math notranslate nohighlight">\(n\)</span> pixels, <span class="math notranslate nohighlight">\(y\)</span> is the measurements of size <span class="math notranslate nohighlight">\(m\)</span>,
<span class="math notranslate nohighlight">\(A:\xset\mapsto \yset\)</span> is a deterministic linear mapping capturing the physics of the acquisition
and <span class="math notranslate nohighlight">\(N:\yset\mapsto \yset\)</span> is a stochastic mapping which characterizes the noise affecting
the measurements.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>Callable</em>) – forward operator function which maps an image to the observed measurements <span class="math notranslate nohighlight">\(x\mapsto y\)</span>.
It is recommended to normalize it to have unit norm.</p></li>
<li><p><strong>A_adjoint</strong> (<em>Callable</em>) – <p>transpose of the forward operator, which should verify the adjointness test.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A_adjoint can be generated automatically using the <a class="reference internal" href="deepinv.physics.adjoint_function.html#deepinv.physics.adjoint_function" title="deepinv.physics.adjoint_function"><code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.physics.adjoint_function()</span></code></a>
method which relies on automatic differentiation, at the cost of a few extra computations per adjoint call.</p>
</div>
</p></li>
<li><p><strong>noise_model</strong> (<em>Callable</em>) – function that adds noise to the measurements <span class="math notranslate nohighlight">\(N(z)\)</span>.
See the noise module for some predefined functions.</p></li>
<li><p><strong>sensor_model</strong> (<em>Callable</em>) – function that incorporates any sensor non-linearities to the sensing process,
such as quantization or saturation, defined as a function <span class="math notranslate nohighlight">\(\eta(z)\)</span>, such that
<span class="math notranslate nohighlight">\(y=\eta\left(N(A(x))\right)\)</span>. By default, the sensor_model is set to the identity <span class="math notranslate nohighlight">\(\eta(z)=z\)</span>.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#int" title="(in Python v3.4)"><em>int</em></a>) – If the operator does not have a closed form pseudoinverse, the conjugate gradient algorithm
is used for computing it, and this parameter fixes the maximum number of conjugate gradient iterations.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – If the operator does not have a closed form pseudoinverse, the conjugate gradient algorithm
is used for computing it, and this parameter fixes the absolute tolerance of the conjugate gradient algorithm.</p></li>
</ul>
</dd>
</dl>
<p><hr /></p>
<dl class="field-list">
<dt class="field-odd">Examples<span class="colon">:</span></dt>
<dd class="field-odd"><p>Blur operator with a basic averaging filter applied to a 32x32 black image with
a single white pixel in the center:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">deepinv.physics.blur</span> <span class="kn">import</span> <span class="n">Blur</span><span class="p">,</span> <span class="n">Downsampling</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span> <span class="c1"># Define black image of size 32x32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># Define one white pixel in the middle</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span> <span class="o">/</span> <span class="mi">9</span> <span class="c1"># Basic 3x3 averaging filter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">physics</span> <span class="o">=</span> <span class="n">Blur</span><span class="p">(</span><span class="nb">filter</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">physics</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Linear operators can also be added. The measurements produced by the resulting
model are <a class="reference internal" href="deepinv.utils.TensorList.html#deepinv.utils.TensorList" title="deepinv.utils.TensorList"><code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.utils.TensorList()</span></code></a> objects, where each entry corresponds to the
measurements of the corresponding operator:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">physics1</span> <span class="o">=</span> <span class="n">Blur</span><span class="p">(</span><span class="nb">filter</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">physics2</span> <span class="o">=</span> <span class="n">Downsampling</span><span class="p">(</span><span class="n">img_size</span><span class="o">=</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span> <span class="nb">filter</span><span class="o">=</span><span class="s2">&quot;gaussian&quot;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">physics</span> <span class="o">=</span> <span class="n">physics1</span> <span class="o">+</span> <span class="n">physics2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">physics</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Linear operators can also be composed by multiplying them:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">physics</span> <span class="o">=</span> <span class="n">physics1</span> <span class="o">*</span> <span class="n">physics2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">physics</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Linear operators also come with an adjoint, a pseudoinverse, and proximal operators in a given norm:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">deepinv.loss.metric</span> <span class="kn">import</span> <span class="n">PSNR</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span> <span class="c1"># Define random 16x16 image</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">physics</span> <span class="o">=</span> <span class="n">Blur</span><span class="p">(</span><span class="nb">filter</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;circular&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">physics</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># Compute measurements</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_dagger</span> <span class="o">=</span> <span class="n">physics</span><span class="o">.</span><span class="n">A_dagger</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># Compute pseudoinverse</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_</span> <span class="o">=</span> <span class="n">physics</span><span class="o">.</span><span class="n">prox_l2</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="mf">0.1</span><span class="p">)</span> <span class="c1"># Compute prox at x=0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">PSNR</span><span class="p">()(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_dagger</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">PSNR</span><span class="p">()(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="c1"># Should be closer to the orginal</span>
<span class="go">tensor([True])</span>
</pre></div>
</div>
<p>The adjoint can be generated automatically using the <a class="reference internal" href="deepinv.physics.adjoint_function.html#deepinv.physics.adjoint_function" title="deepinv.physics.adjoint_function"><code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.physics.adjoint_function()</span></code></a> method
which relies on automatic differentiation, at the cost of a few extra computations per adjoint call:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">deepinv.physics</span> <span class="kn">import</span> <span class="n">LinearPhysics</span><span class="p">,</span> <span class="n">adjoint_function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">shifts</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span> <span class="c1"># Shift image by one pixel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">physics</span> <span class="o">=</span> <span class="n">LinearPhysics</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="n">A</span><span class="p">,</span> <span class="n">A_adjoint</span><span class="o">=</span><span class="n">adjoint_function</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">physics</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">physics</span><span class="o">.</span><span class="n">A_adjoint</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span> <span class="c1"># We have A^T(A(x)) = x</span>
<span class="go">True</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deepinv.physics.LinearPhysics.A_A_adjoint">
<span class="sig-name descname"><span class="pre">A_A_adjoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/physics/forward.html#LinearPhysics.A_A_adjoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.physics.LinearPhysics.A_A_adjoint" title="Link to this definition"></a></dt>
<dd><p>A helper function that computes <span class="math notranslate nohighlight">\(A A^{\top}y\)</span>.</p>
<p>This function can speed up computation when <span class="math notranslate nohighlight">\(A A^{\top}\)</span> is available in closed form.
Otherwise it just cals <code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.physics.LinearPhysics.A()</span></code> and <a class="reference internal" href="#deepinv.physics.LinearPhysics.A_adjoint" title="deepinv.physics.LinearPhysics.A_adjoint"><code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.physics.LinearPhysics.A_adjoint()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> (<a class="reference external" href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – measurement.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.Tensor) the product <span class="math notranslate nohighlight">\(AA^{\top}y\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.physics.LinearPhysics.A_adjoint">
<span class="sig-name descname"><span class="pre">A_adjoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/physics/forward.html#LinearPhysics.A_adjoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.physics.LinearPhysics.A_adjoint" title="Link to this definition"></a></dt>
<dd><p>Computes transpose of the forward operator <span class="math notranslate nohighlight">\(\tilde{x} = A^{\top}y\)</span>.
If <span class="math notranslate nohighlight">\(A\)</span> is linear, it should be the exact transpose of the forward matrix.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the problem is non-linear, there is not a well-defined transpose operation,
but defining one can be useful for some reconstruction networks, such as <code class="docutils literal notranslate"><span class="pre">deepinv.models.ArtifactRemoval</span></code>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<a class="reference external" href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – measurements.</p></li>
<li><p><strong>params</strong> (<em>None</em><em>, </em><a class="reference external" href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – optional additional parameters for the adjoint operator.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.Tensor) linear reconstruction <span class="math notranslate nohighlight">\(\tilde{x} = A^{\top}y\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.physics.LinearPhysics.A_adjoint_A">
<span class="sig-name descname"><span class="pre">A_adjoint_A</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/physics/forward.html#LinearPhysics.A_adjoint_A"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.physics.LinearPhysics.A_adjoint_A" title="Link to this definition"></a></dt>
<dd><p>A helper function that computes <span class="math notranslate nohighlight">\(A^{\top}Ax\)</span>.</p>
<p>This function can speed up computation when <span class="math notranslate nohighlight">\(A^{\top}A\)</span> is available in closed form.
Otherwise it just cals <code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.physics.LinearPhysics.A()</span></code> and <a class="reference internal" href="#deepinv.physics.LinearPhysics.A_adjoint" title="deepinv.physics.LinearPhysics.A_adjoint"><code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.physics.LinearPhysics.A_adjoint()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference external" href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – signal/image.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.Tensor) the product <span class="math notranslate nohighlight">\(A^{\top}Ax\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.physics.LinearPhysics.A_dagger">
<span class="sig-name descname"><span class="pre">A_dagger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/physics/forward.html#LinearPhysics.A_dagger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.physics.LinearPhysics.A_dagger" title="Link to this definition"></a></dt>
<dd><p>Computes the solution in <span class="math notranslate nohighlight">\(x\)</span> to <span class="math notranslate nohighlight">\(y = Ax\)</span> using the
<a class="reference external" href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">conjugate gradient method</a>,
see <a class="reference internal" href="deepinv.optim.utils.conjugate_gradient.html#deepinv.optim.utils.conjugate_gradient" title="deepinv.optim.utils.conjugate_gradient"><code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.optim.utils.conjugate_gradient()</span></code></a>.</p>
<p>If the size of <span class="math notranslate nohighlight">\(y\)</span> is larger than <span class="math notranslate nohighlight">\(x\)</span> (overcomplete problem), it computes <span class="math notranslate nohighlight">\((A^{\top} A)^{-1} A^{\top} y\)</span>,
otherwise (incomplete problem) it computes <span class="math notranslate nohighlight">\(A^{\top} (A A^{\top})^{-1} y\)</span>.</p>
<p>This function can be overwritten by a more efficient pseudoinverse in cases where closed form formulas exist.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> (<a class="reference external" href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – a measurement <span class="math notranslate nohighlight">\(y\)</span> to reconstruct via the pseudoinverse.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.Tensor) The reconstructed image <span class="math notranslate nohighlight">\(x\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.physics.LinearPhysics.A_vjp">
<span class="sig-name descname"><span class="pre">A_vjp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/physics/forward.html#LinearPhysics.A_vjp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.physics.LinearPhysics.A_vjp" title="Link to this definition"></a></dt>
<dd><p>Computes the product between a vector <span class="math notranslate nohighlight">\(v\)</span> and the Jacobian of the forward operator <span class="math notranslate nohighlight">\(A\)</span> evaluated at <span class="math notranslate nohighlight">\(x\)</span>, defined as:</p>
<div class="math notranslate nohighlight">
\[A_{vjp}(x, v) = \left. \frac{\partial A}{\partial x}  \right|_x^\top  v = \conj{A} v.\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference external" href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – signal/image.</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – vector.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.Tensor) the VJP product between <span class="math notranslate nohighlight">\(v\)</span> and the Jacobian.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.physics.LinearPhysics.__add__">
<span class="sig-name descname"><span class="pre">__add__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/physics/forward.html#LinearPhysics.__add__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.physics.LinearPhysics.__add__" title="Link to this definition"></a></dt>
<dd><p>Stacks two linear forward operators <span class="math notranslate nohighlight">\(A = \begin{bmatrix} A_1 \\ A_2 \end{bmatrix}\)</span> via the add operation.</p>
<p>The measurements produced by the resulting model are <a class="reference internal" href="deepinv.utils.TensorList.html#deepinv.utils.TensorList" title="deepinv.utils.TensorList"><code class="xref py py-class docutils literal notranslate"><span class="pre">deepinv.utils.TensorList</span></code></a> objects, where
each entry corresponds to the measurements of the corresponding operator.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using the <code class="docutils literal notranslate"><span class="pre">__add__</span></code> operator between two noise objects, the operation will retain only the second
noise.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#deepinv.physics.LinearPhysics" title="deepinv.physics.LinearPhysics"><em>deepinv.physics.LinearPhysics</em></a>) – Physics operator <span class="math notranslate nohighlight">\(A_2\)</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(deepinv.physics.LinearPhysics) stacked operator</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.physics.LinearPhysics.__mul__">
<span class="sig-name descname"><span class="pre">__mul__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/physics/forward.html#LinearPhysics.__mul__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.physics.LinearPhysics.__mul__" title="Link to this definition"></a></dt>
<dd><p>Concatenates two linear forward operators <span class="math notranslate nohighlight">\(A = A_1\circ A_2\)</span> via the * operation</p>
<p>The resulting linear operator keeps the noise and sensor models of <span class="math notranslate nohighlight">\(A_1\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#deepinv.physics.LinearPhysics" title="deepinv.physics.LinearPhysics"><em>deepinv.physics.LinearPhysics</em></a>) – Physics operator <span class="math notranslate nohighlight">\(A_2\)</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(deepinv.physics.LinearPhysics) concatenated operator</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.physics.LinearPhysics.adjointness_test">
<span class="sig-name descname"><span class="pre">adjointness_test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/physics/forward.html#LinearPhysics.adjointness_test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.physics.LinearPhysics.adjointness_test" title="Link to this definition"></a></dt>
<dd><p>Numerically check that <span class="math notranslate nohighlight">\(A^{\top}\)</span> is indeed the adjoint of <span class="math notranslate nohighlight">\(A\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>u</strong> (<a class="reference external" href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – initialisation point of the adjointness test method</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(float) a quantity that should be theoretically 0. In practice, it should be of the order of the chosen dtype precision (i.e. single or double).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.physics.LinearPhysics.compute_norm">
<span class="sig-name descname"><span class="pre">compute_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/physics/forward.html#LinearPhysics.compute_norm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.physics.LinearPhysics.compute_norm" title="Link to this definition"></a></dt>
<dd><p>Computes the spectral <span class="math notranslate nohighlight">\(\ell_2\)</span> norm (Lipschitz constant) of the operator</p>
<p><span class="math notranslate nohighlight">\(A^{\top}A\)</span>, i.e., <span class="math notranslate nohighlight">\(\|A^{\top}A\|\)</span>.</p>
<p>using the <a class="reference external" href="https://en.wikipedia.org/wiki/Power_iteration">power method</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x0</strong> (<a class="reference external" href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – initialisation point of the algorithm</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#int" title="(in Python v3.4)"><em>int</em></a>) – maximum number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – relative variation criterion for convergence</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) – print information</p></li>
</ul>
</dd>
<dt class="field-even">Returns z<span class="colon">:</span></dt>
<dd class="field-even"><p>(float) spectral norm of <span class="math notranslate nohighlight">\(\conj{A} A\)</span>, i.e., <span class="math notranslate nohighlight">\(\|\conj{A} A\|\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.physics.LinearPhysics.prox_l2">
<span class="sig-name descname"><span class="pre">prox_l2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/physics/forward.html#LinearPhysics.prox_l2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.physics.LinearPhysics.prox_l2" title="Link to this definition"></a></dt>
<dd><p>Computes proximal operator of <span class="math notranslate nohighlight">\(f(x) = \frac{1}{2}\|Ax-y\|^2\)</span>, i.e.,</p>
<div class="math notranslate nohighlight">
\[\underset{x}{\arg\min} \; \frac{\gamma}{2}\|Ax-y\|^2 + \frac{1}{2}\|x-z\|^2\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<a class="reference external" href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – measurements tensor</p></li>
<li><p><strong>z</strong> (<a class="reference external" href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – signal tensor</p></li>
<li><p><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – hyperparameter of the proximal operator</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.Tensor) estimated signal tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-linearphysics">
<span id="sphx-glr-backref-deepinv-physics-linearphysics"></span><h2>Examples using <code class="docutils literal notranslate"><span class="pre">LinearPhysics</span></code>:<a class="headerlink" href="#examples-using-linearphysics" title="Link to this heading"></a></h2>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="In this example, we investigate a simple 2D Radio Interferometry (RI) imaging task with deepinverse.  The following example and data are taken from Aghabiglou et al. (2024).  If you are interested in RI imaging problem and would like to see more examples or try the state-of-the-art algorithms, please check BASPLib."><img alt="" src="../_images/sphx_glr_demo_ri_basic_thumb.png" />
<p><a class="reference internal" href="../auto_examples/advanced/demo_ri_basic.html#sphx-glr-auto-examples-advanced-demo-ri-basic-py"><span class="std std-ref">Radio interferometric imaging with deepinverse</span></a></p>
  <div class="sphx-glr-thumbnail-title">Radio interferometric imaging with deepinverse</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows you how to train various networks using adversarial training for deblurring problems. We demonstrate running training and inference using a conditional GAN (i.e. DeblurGAN), CSGM, AmbientGAN and UAIR implemented in the library, and how to simply train your own GAN by using deepinv.training.AdversarialTrainer. These examples can also be easily extended to train more complicated GANs such as CycleGAN."><img alt="" src="../_images/sphx_glr_demo_gan_imaging_thumb.png" />
<p><a class="reference internal" href="../auto_examples/adversarial-learning/demo_gan_imaging.html#sphx-glr-auto-examples-adversarial-learning-demo-gan-imaging-py"><span class="std std-ref">Imaging inverse problems with adversarial networks</span></a></p>
  <div class="sphx-glr-thumbnail-title">Imaging inverse problems with adversarial networks</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we show how to stack and concatenate forward operators to create new operators. In particular, we create a pan-sharpening operator by stacking a downsampling and a color-to-grayscale operators."><img alt="" src="../_images/sphx_glr_demo_pansharpening_thumb.png" />
<p><a class="reference internal" href="../auto_examples/basics/demo_pansharpening.html#sphx-glr-auto-examples-basics-demo-pansharpening-py"><span class="std std-ref">Stacking and concatenating forward operators.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Stacking and concatenating forward operators.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This code shows how to reconstruct a noisy and incomplete image using the deep image prior."><img alt="" src="../_images/sphx_glr_demo_dip_thumb.png" />
<p><a class="reference internal" href="../auto_examples/basics/demo_dip.html#sphx-glr-auto-examples-basics-demo-dip-py"><span class="std std-ref">Reconstructing an image using the deep image prior.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Reconstructing an image using the deep image prior.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to create your own dataset for deep image inverse problems from a base dataset of images. Here we use Set3C as a base dataset of natural images. This base dataset contains 3 images."><img alt="" src="../_images/sphx_glr_demo_dataset_thumb.png" />
<p><a class="reference internal" href="../auto_examples/basics/demo_dataset.html#sphx-glr-auto-examples-basics-demo-dataset-py"><span class="std std-ref">Creating your own dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">Creating your own dataset</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="While deepinv offers a large number of forward operators in the physics module, you might want to create your own forward operator for your specific imaging problem. This example walks you through the creation of a custom forward operator."><img alt="" src="../_images/sphx_glr_demo_physics_thumb.png" />
<p><a class="reference internal" href="../auto_examples/basics/demo_physics.html#sphx-glr-auto-examples-basics-demo-physics-py"><span class="std std-ref">Creating a forward operator.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Creating a forward operator.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example provides a tour of 3D blur operators in the library. In particular, we show how to use Diffraction Blurs (Fresnel diffraction) to simulate  fluorescence microscopes."><img alt="" src="../_images/sphx_glr_demo_microscopy_3d_thumb.png" />
<p><a class="reference internal" href="../auto_examples/basics/demo_microscopy_3d.html#sphx-glr-auto-examples-basics-demo-microscopy-3d-py"><span class="std std-ref">3D diffraction PSF</span></a></p>
  <div class="sphx-glr-thumbnail-title">3D diffraction PSF</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to train a simple reconstruction network for an image inpainting inverse problem."><img alt="" src="../_images/sphx_glr_demo_train_inpainting_thumb.png" />
<p><a class="reference internal" href="../auto_examples/basics/demo_train_inpainting.html#sphx-glr-auto-examples-basics-demo-train-inpainting-py"><span class="std std-ref">Training a reconstruction network.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Training a reconstruction network.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example provides a tour of some of the forward operators implemented in DeepInverse. We restrict ourselves to operators where the signal is a 2D image. The full list of operators can be found in here."><img alt="" src="../_images/sphx_glr_demo_physics_tour_thumb.png" />
<p><a class="reference internal" href="../auto_examples/basics/demo_physics_tour.html#sphx-glr-auto-examples-basics-demo-physics-tour-py"><span class="std std-ref">A tour of forward sensing operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">A tour of forward sensing operators</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we show how to solve a deblurring inverse problem using an explicit prior."><img alt="" src="../_images/sphx_glr_demo_custom_prior_thumb.png" />
<p><a class="reference internal" href="../auto_examples/basics/demo_custom_prior.html#sphx-glr-auto-examples-basics-demo-custom-prior-py"><span class="std std-ref">Image deblurring with custom deep explicit prior.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Image deblurring with custom deep explicit prior.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Models can be saved and loaded in the same way as in PyTorch. In this example, we show how to define, load and save a model. For the purpose of the example, we choose an unfolded Chambolle Pock algorithm as the model. The architecture of the model and its training are described in the constrained unfolded demo."><img alt="" src="../_images/sphx_glr_demo_loading_thumb.png" />
<p><a class="reference internal" href="../auto_examples/basics/demo_loading.html#sphx-glr-auto-examples-basics-demo-loading-py"><span class="std std-ref">Saving and loading models</span></a></p>
  <div class="sphx-glr-thumbnail-title">Saving and loading models</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example provides a tour of 2D blur operators in DeepInv. In particular, we show how to use DiffractionBlurs (Fresnel diffraction), motion blurs and space varying blurs."><img alt="" src="../_images/sphx_glr_demo_blur_tour_thumb.png" />
<p><a class="reference internal" href="../auto_examples/basics/demo_blur_tour.html#sphx-glr-auto-examples-basics-demo-blur-tour-py"><span class="std std-ref">A tour of blur operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">A tour of blur operators</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use a standard TV prior for image deblurring. The problem writes as y = Ax + \epsilon where A is a convolutional operator and \epsilon is the realization of some Gaussian noise. The goal is to recover the original image x from the blurred and noisy image y. The TV prior is used to regularize the problem."><img alt="" src="../_images/sphx_glr_demo_TV_minimisation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/optimization/demo_TV_minimisation.html#sphx-glr-auto-examples-optimization-demo-tv-minimisation-py"><span class="std std-ref">Image deblurring with Total-Variation (TV) prior</span></a></p>
  <div class="sphx-glr-thumbnail-title">Image deblurring with Total-Variation (TV) prior</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use a standard wavelet prior for image inpainting. The problem writes as y = Ax + \epsilon where A is a mask and \epsilon is the realization of some Gaussian noise. The goal is to recover the original image x from the blurred and noisy image y. The wavelet prior is used to regularize the problem."><img alt="" src="../_images/sphx_glr_demo_wavelet_prior_thumb.png" />
<p><a class="reference internal" href="../auto_examples/optimization/demo_wavelet_prior.html#sphx-glr-auto-examples-optimization-demo-wavelet-prior-py"><span class="std std-ref">Image inpainting with wavelet prior</span></a></p>
  <div class="sphx-glr-thumbnail-title">Image inpainting with wavelet prior</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example we use the expected patch log likelihood (EPLL) prior EPLL proposed in &quot;From learning models of natural image patches to whole image restoration&quot;.  for denoising and inpainting of natural images. To this end, we consider the inverse problem y = Ax+\epsilon, where A is either the identity (for denoising) or a masking operator (for inpainting) and \epsilon\sim\mathcal{N}(0,\sigma^2 I) is white Gaussian noise with standard deviation \sigma."><img alt="" src="../_images/sphx_glr_demo_epll_thumb.png" />
<p><a class="reference internal" href="../auto_examples/patch-priors/demo_epll.html#sphx-glr-auto-examples-patch-priors-demo-epll-py"><span class="std std-ref">Expected Patch Log Likelihood (EPLL) for Denoising and Inpainting</span></a></p>
  <div class="sphx-glr-thumbnail-title">Expected Patch Log Likelihood (EPLL) for Denoising and Inpainting</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example we use patch priors for limited angle computed tomography. More precisely, we consider the  inverse problem y = \mathrm{noisy}(Ax), where A is the discretized Radon transform with 100 equispace angles between 20 and 160 degrees. For the reconstruction, we minimize the variational problem"><img alt="" src="../_images/sphx_glr_demo_patch_priors_CT_thumb.png" />
<p><a class="reference internal" href="../auto_examples/patch-priors/demo_patch_priors_CT.html#sphx-glr-auto-examples-patch-priors-demo-patch-priors-ct-py"><span class="std std-ref">Patch priors for limited-angle computed tomography</span></a></p>
  <div class="sphx-glr-thumbnail-title">Patch priors for limited-angle computed tomography</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This is a simple example to show how to use a mirror descent algorithm for solving an inverse problem with Poisson noise."><img alt="" src="../_images/sphx_glr_demo_PnP_mirror_descent_thumb.png" />
<p><a class="reference internal" href="../auto_examples/plug-and-play/demo_PnP_mirror_descent.html#sphx-glr-auto-examples-plug-and-play-demo-pnp-mirror-descent-py"><span class="std std-ref">Plug-and-Play algorithm with Mirror Descent for Poisson noise inverse problems.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plug-and-Play algorithm with Mirror Descent for Poisson noise inverse problems.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use a standart PnP algorithm with DnCNN denoiser for computed tomography."><img alt="" src="../_images/sphx_glr_demo_vanilla_PnP_thumb.png" />
<p><a class="reference internal" href="../auto_examples/plug-and-play/demo_vanilla_PnP.html#sphx-glr-auto-examples-plug-and-play-demo-vanilla-pnp-py"><span class="std std-ref">Vanilla PnP for computed tomography (CT).</span></a></p>
  <div class="sphx-glr-thumbnail-title">Vanilla PnP for computed tomography (CT).</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use the DPIR method to solve a PnP image deblurring problem. The DPIR method is described in the following paper: Zhang, K., Zuo, W., Gu, S., &amp; Zhang, L. (2017).  Learning deep CNN denoiser prior for image restoration.  In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3929-3938)."><img alt="" src="../_images/sphx_glr_demo_PnP_DPIR_deblur_thumb.png" />
<p><a class="reference internal" href="../auto_examples/plug-and-play/demo_PnP_DPIR_deblur.html#sphx-glr-auto-examples-plug-and-play-demo-pnp-dpir-deblur-py"><span class="std std-ref">DPIR method for PnP image deblurring.</span></a></p>
  <div class="sphx-glr-thumbnail-title">DPIR method for PnP image deblurring.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We use as plug-in denoiser the Gradient-Step Denoiser (GSPnP) which provides an explicit prior."><img alt="" src="../_images/sphx_glr_demo_RED_GSPnP_SR_thumb.png" />
<p><a class="reference internal" href="../auto_examples/plug-and-play/demo_RED_GSPnP_SR.html#sphx-glr-auto-examples-plug-and-play-demo-red-gspnp-sr-py"><span class="std std-ref">Regularization by Denoising (RED) for Super-Resolution.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Regularization by Denoising (RED) for Super-Resolution.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to define your own optimization algorithm. For example, here, we implement the Condat-Vu Primal-Dual algorithm, and apply it for Single Pixel Camera reconstruction."><img alt="" src="../_images/sphx_glr_demo_PnP_custom_optim_thumb.png" />
<p><a class="reference internal" href="../auto_examples/plug-and-play/demo_PnP_custom_optim.html#sphx-glr-auto-examples-plug-and-play-demo-pnp-custom-optim-py"><span class="std std-ref">PnP with custom optimization algorithm (Condat-Vu Primal-Dual)</span></a></p>
  <div class="sphx-glr-thumbnail-title">PnP with custom optimization algorithm (Condat-Vu Primal-Dual)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This code shows you how to use sampling algorithms to quantify uncertainty of a reconstruction from incomplete and noisy measurements."><img alt="" src="../_images/sphx_glr_demo_sampling_thumb.png" />
<p><a class="reference internal" href="../auto_examples/sampling/demo_sampling.html#sphx-glr-auto-examples-sampling-demo-sampling-py"><span class="std std-ref">Uncertainty quantification with PnP-ULA.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Uncertainty quantification with PnP-ULA.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This code shows you how to use the DDRM diffusion algorithm to reconstruct images and also compute the uncertainty of a reconstruction from incomplete and noisy measurements."><img alt="" src="../_images/sphx_glr_demo_ddrm_thumb.png" />
<p><a class="reference internal" href="../auto_examples/sampling/demo_ddrm.html#sphx-glr-auto-examples-sampling-demo-ddrm-py"><span class="std std-ref">Image reconstruction with a diffusion model</span></a></p>
  <div class="sphx-glr-thumbnail-title">Image reconstruction with a diffusion model</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This code shows how to build your custom sampling kernel. Here we build a preconditioned Unadjusted Langevin Algorithm (PreconULA) that takes advantage of the singular value decomposition of the forward operator to accelerate the sampling."><img alt="" src="../_images/sphx_glr_demo_custom_kernel_thumb.png" />
<p><a class="reference internal" href="../auto_examples/sampling/demo_custom_kernel.html#sphx-glr-auto-examples-sampling-demo-custom-kernel-py"><span class="std std-ref">Building your custom sampling algorithm.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Building your custom sampling algorithm.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we will go over the steps in the Diffusion Posterior Sampling (DPS) algorithm introduced in Chung et al. The full algorithm is implemented in deepinv.sampling.DPS."><img alt="" src="../_images/sphx_glr_demo_dps_thumb.png" />
<p><a class="reference internal" href="../auto_examples/sampling/demo_dps.html#sphx-glr-auto-examples-sampling-demo-dps-py"><span class="std std-ref">Implementing DPS</span></a></p>
  <div class="sphx-glr-thumbnail-title">Implementing DPS</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we revisit the implementation of the DiffPIR diffusion algorithm for image reconstruction from Zhou et al.. The full algorithm is implemented in deepinv.sampling.DiffPIR."><img alt="" src="../_images/sphx_glr_demo_diffpir_thumb.png" />
<p><a class="reference internal" href="../auto_examples/sampling/demo_diffpir.html#sphx-glr-auto-examples-sampling-demo-diffpir-py"><span class="std std-ref">Implementing DiffPIR</span></a></p>
  <div class="sphx-glr-thumbnail-title">Implementing DiffPIR</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We demonstrate self-supervised learning with measurement splitting, to train a denoiser network on the MNIST dataset. The physics here is noisy computed tomography, as is the case in Noise2Inverse. Note this example can also be easily applied to undersampled multicoil MRI as is the case in SSDU."><img alt="" src="../_images/sphx_glr_demo_splitting_loss_thumb.png" />
<p><a class="reference internal" href="../auto_examples/self-supervised-learning/demo_splitting_loss.html#sphx-glr-auto-examples-self-supervised-learning-demo-splitting-loss-py"><span class="std std-ref">Self-supervised learning with measurement splitting</span></a></p>
  <div class="sphx-glr-thumbnail-title">Self-supervised learning with measurement splitting</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates various geometric image transformations implemented in deepinv that can be used in Equivariant Imaging (EI) for self-supervised learning:"><img alt="" src="../_images/sphx_glr_demo_ei_transforms_thumb.png" />
<p><a class="reference internal" href="../auto_examples/self-supervised-learning/demo_ei_transforms.html#sphx-glr-auto-examples-self-supervised-learning-demo-ei-transforms-py"><span class="std std-ref">Image transformations for Equivariant Imaging</span></a></p>
  <div class="sphx-glr-thumbnail-title">Image transformations for Equivariant Imaging</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We demonstrate the self-supervised Artifact2Artifact loss for solving an undersampled sequential MRI reconstruction problem without ground truth."><img alt="" src="../_images/sphx_glr_demo_artifact2artifact_thumb.png" />
<p><a class="reference internal" href="../auto_examples/self-supervised-learning/demo_artifact2artifact.html#sphx-glr-auto-examples-self-supervised-learning-demo-artifact2artifact-py"><span class="std std-ref">Self-supervised MRI reconstruction with Artifact2Artifact</span></a></p>
  <div class="sphx-glr-thumbnail-title">Self-supervised MRI reconstruction with Artifact2Artifact</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows you how to train a denoiser network in a fully self-supervised way, i.e., using noisy images with unknown noise level only via the UNSURE loss, which is introduced in https://arxiv.org/abs/2409.01985."><img alt="" src="../_images/sphx_glr_demo_unsure_thumb.png" />
<p><a class="reference internal" href="../auto_examples/self-supervised-learning/demo_unsure.html#sphx-glr-auto-examples-self-supervised-learning-demo-unsure-py"><span class="std std-ref">Self-supervised denoising with the UNSURE loss.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Self-supervised denoising with the UNSURE loss.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows you how to train a denoiser network in a fully self-supervised way, i.e., using noisy images only via the SURE loss, which exploits knowledge about the noise distribution."><img alt="" src="../_images/sphx_glr_demo_sure_denoising_thumb.png" />
<p><a class="reference internal" href="../auto_examples/self-supervised-learning/demo_sure_denoising.html#sphx-glr-auto-examples-self-supervised-learning-demo-sure-denoising-py"><span class="std std-ref">Self-supervised denoising with the SURE loss.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Self-supervised denoising with the SURE loss.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows you how to train a denoiser network in a fully self-supervised way, i.e., using noisy images only via the Neighbor2Neighbor loss, which exploits the local correlation of natural images."><img alt="" src="../_images/sphx_glr_demo_n2n_denoising_thumb.png" />
<p><a class="reference internal" href="../auto_examples/self-supervised-learning/demo_n2n_denoising.html#sphx-glr-auto-examples-self-supervised-learning-demo-n2n-denoising-py"><span class="std std-ref">Self-supervised denoising with the Neighbor2Neighbor loss.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Self-supervised denoising with the Neighbor2Neighbor loss.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows you how to train a reconstruction network for an MRI inverse problem on a fully self-supervised way, i.e., using measurement data only."><img alt="" src="../_images/sphx_glr_demo_equivariant_imaging_thumb.png" />
<p><a class="reference internal" href="../auto_examples/self-supervised-learning/demo_equivariant_imaging.html#sphx-glr-auto-examples-self-supervised-learning-demo-equivariant-imaging-py"><span class="std std-ref">Self-supervised learning with Equivariant Imaging for MRI.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Self-supervised learning with Equivariant Imaging for MRI.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows you how to train a reconstruction network for an inpainting inverse problem on a fully self-supervised way, i.e., using measurement data only."><img alt="" src="../_images/sphx_glr_demo_multioperator_imaging_thumb.png" />
<p><a class="reference internal" href="../auto_examples/self-supervised-learning/demo_multioperator_imaging.html#sphx-glr-auto-examples-self-supervised-learning-demo-multioperator-imaging-py"><span class="std std-ref">Self-supervised learning from incomplete measurements of multiple operators.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Self-supervised learning from incomplete measurements of multiple operators.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to implement the LISTA algorithm for a compressed sensing problem. In a nutshell, LISTA is an unfolded proximal gradient algorithm involving a soft-thresholding proximal operator with learnable thresholding parameters."><img alt="" src="../_images/sphx_glr_demo_LISTA_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_LISTA.html#sphx-glr-auto-examples-unfolded-demo-lista-py"><span class="std std-ref">Learned Iterative Soft-Thresholding Algorithm (LISTA) for compressed sensing</span></a></p>
  <div class="sphx-glr-thumbnail-title">Learned Iterative Soft-Thresholding Algorithm (LISTA) for compressed sensing</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This is a simple example to show how to use vanilla unfolded Plug-and-Play. The DnCNN denoiser and the algorithm parameters (stepsize, regularization parameters) are trained jointly. For simplicity, we show how to train the algorithm on a  small dataset. For optimal results, use a larger dataset. For visualizing the training, you can use Weight&amp;Bias (wandb) by setting wandb_vis=True."><img alt="" src="../_images/sphx_glr_demo_vanilla_unfolded_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_vanilla_unfolded.html#sphx-glr-auto-examples-unfolded-demo-vanilla-unfolded-py"><span class="std std-ref">Vanilla Unfolded algorithm for super-resolution</span></a></p>
  <div class="sphx-glr-thumbnail-title">Vanilla Unfolded algorithm for super-resolution</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to implement a learned unrolled proximal gradient descent algorithm with a custom prior function. The algorithm is trained on a dataset of compressed sensing measurements of MNIST images."><img alt="" src="../_images/sphx_glr_demo_custom_prior_unfolded_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_custom_prior_unfolded.html#sphx-glr-auto-examples-unfolded-demo-custom-prior-unfolded-py"><span class="std std-ref">Learned iterative custom prior</span></a></p>
  <div class="sphx-glr-thumbnail-title">Learned iterative custom prior</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This a toy example to show you how to use DEQ to solve a deblurring problem.  Note that this is a small dataset for training. For optimal results, use a larger dataset. For visualizing the training, you can use Weight&amp;Bias (wandb) by setting wandb_vis=True."><img alt="" src="../_images/sphx_glr_demo_DEQ_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_DEQ.html#sphx-glr-auto-examples-unfolded-demo-deq-py"><span class="std std-ref">Deep Equilibrium (DEQ) algorithms for image deblurring</span></a></p>
  <div class="sphx-glr-thumbnail-title">Deep Equilibrium (DEQ) algorithms for image deblurring</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Adler, Jonas, and Ozan Öktem.  &quot;Learned primal-dual reconstruction.&quot;  IEEE transactions on medical imaging 37.6 (2018): 1322-1332."><img alt="" src="../_images/sphx_glr_demo_learned_primal_dual_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_learned_primal_dual.html#sphx-glr-auto-examples-unfolded-demo-learned-primal-dual-py"><span class="std std-ref">Learned Primal-Dual algorithm for CT scan.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Learned Primal-Dual algorithm for CT scan.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Image inpainting consists in solving y = Ax where A is a mask operator. This problem can be reformulated as the following minimization problem:"><img alt="" src="../_images/sphx_glr_demo_unfolded_constrained_LISTA_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_unfolded_constrained_LISTA.html#sphx-glr-auto-examples-unfolded-demo-unfolded-constrained-lista-py"><span class="std std-ref">Unfolded Chambolle-Pock for constrained image inpainting</span></a></p>
  <div class="sphx-glr-thumbnail-title">Unfolded Chambolle-Pock for constrained image inpainting</div>
</div></div></section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="deepinv.physics.Physics.html" class="btn btn-neutral float-left" title="Physics" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="deepinv.physics.DecomposablePhysics.html" class="btn btn-neutral float-right" title="DecomposablePhysics" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, DeepInv.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEKFKYSGR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NSEKFKYSGR', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>