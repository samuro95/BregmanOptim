

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Self-supervised learning with Equivariant Imaging for MRI. &mdash; deepinverse 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
    <link rel="shortcut icon" href="../../_static/logo.ico"/>
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=2709fde1"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=35a8b989"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Self-supervised learning from incomplete measurements of multiple operators." href="demo_multioperator_imaging.html" />
    <link rel="prev" title="Self-supervised denoising with the Neighbor2Neighbor loss." href="demo_n2n_denoising.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/deepinv_logolarge.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.physics.html">Physics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.loss.html">Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.metric.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.transform.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.denoisers.html">Denoisers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.optim.html">Optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.iterative.html">Iterative Reconstruction (PnP, RED, etc.)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.unfolded.html">Unfolded Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.sampling.html">Diffusion Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.other_models.html">Other Reconstruction Methods</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#advanced">Advanced</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#adversarial-learning">Adversarial Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#basics">Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#optimization">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#patch-priors">Patch Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#plug-and-play">Plug-and-Play</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#sampling">Sampling</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#self-supervised-learning">Self-Supervised Learning</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="demo_splitting_loss.html">Self-supervised learning with measurement splitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="demo_ei_transforms.html">Image transformations for Equivariant Imaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="demo_artifact2artifact.html">Self-supervised MRI reconstruction with Artifact2Artifact</a></li>
<li class="toctree-l3"><a class="reference internal" href="demo_artifact2artifact.html#test-the-model">Test the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="demo_unsure.html">Self-supervised denoising with the UNSURE loss.</a></li>
<li class="toctree-l3"><a class="reference internal" href="demo_sure_denoising.html">Self-supervised denoising with the SURE loss.</a></li>
<li class="toctree-l3"><a class="reference internal" href="demo_n2n_denoising.html">Self-supervised denoising with the Neighbor2Neighbor loss.</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Self-supervised learning with Equivariant Imaging for MRI.</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#setup-paths-for-data-loading-and-results">Setup paths for data loading and results.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#load-base-image-datasets-and-degradation-operators">Load base image datasets and degradation operators.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generate-a-dataset-of-knee-images-and-load-it">Generate a dataset of knee images and load it.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#set-up-the-reconstruction-network">Set up the reconstruction network</a></li>
<li class="toctree-l4"><a class="reference internal" href="#set-up-the-training-parameters">Set up the training parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#train-the-network">Train the network</a></li>
<li class="toctree-l4"><a class="reference internal" href="#test-the-network">Test the network</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="demo_multioperator_imaging.html">Self-supervised learning from incomplete measurements of multiple operators.</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#unfolded">Unfolded</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.multigpu.html">Using multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.notation.html">Math Notation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.contributing.html">How to Contribute</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">deepinverse</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Examples</a></li>
      <li class="breadcrumb-item active">Self-supervised learning with Equivariant Imaging for MRI.</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/auto_examples/self-supervised-learning/demo_equivariant_imaging.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-self-supervised-learning-demo-equivariant-imaging-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="self-supervised-learning-with-equivariant-imaging-for-mri">
<span id="sphx-glr-auto-examples-self-supervised-learning-demo-equivariant-imaging-py"></span><h1>Self-supervised learning with Equivariant Imaging for MRI.<a class="headerlink" href="#self-supervised-learning-with-equivariant-imaging-for-mri" title="Link to this heading"></a></h1>
<p>This example shows you how to train a reconstruction network for an MRI inverse problem on a fully self-supervised way, i.e., using measurement data only.</p>
<p>The equivariant imaging loss is presented in <a class="reference external" href="http://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Equivariant_Imaging_Learning_Beyond_the_Range_Space_ICCV_2021_paper.pdf">“Equivariant Imaging: Learning Beyond the Range Space”</a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">deepinv</span> <span class="k">as</span> <span class="nn">dinv</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class"><span class="n">Path</span></a>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">deepinv.optim.prior</span> <span class="kn">import</span> <span class="n">PnP</span>
<span class="kn">from</span> <span class="nn">deepinv.utils.demo</span> <span class="kn">import</span> <span class="n">load_dataset</span><span class="p">,</span> <span class="n">load_degradation</span><span class="p">,</span> <span class="n">demo_mri_model</span>
<span class="kn">from</span> <span class="nn">deepinv.models.utils</span> <span class="kn">import</span> <span class="n">get_weights_url</span>
</pre></div>
</div>
<section id="setup-paths-for-data-loading-and-results">
<h2>Setup paths for data loading and results.<a class="headerlink" href="#setup-paths-for-data-loading-and-results" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class"><span class="n">Path</span></a><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ORIGINAL_DATA_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;datasets&quot;</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DATA_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;measurements&quot;</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CKPT_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;ckpts&quot;</span>

<span class="c1"># Set the global random seed from pytorch to ensure reproducibility of the example.</span>
<a href="http://pytorch.org/docs/2.0/generated/torch.manual_seed.html#torch.manual_seed" title="torch.manual_seed" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_freer_gpu</span><span class="p">()</span> <span class="k">if</span> <a href="http://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
</pre></div>
</div>
</section>
<section id="load-base-image-datasets-and-degradation-operators">
<h2>Load base image datasets and degradation operators.<a class="headerlink" href="#load-base-image-datasets-and-degradation-operators" title="Link to this heading"></a></h2>
<p>In this example, we use a subset of the single-coil <a class="reference external" href="https://fastmri.org/">FastMRI dataset</a>
as the base image dataset. It consists of 973 knee images of size 320x320.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We reduce to the size to 128x128 for faster training in the demo.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">operation</span></a> <span class="o">=</span> <span class="s2">&quot;MRI&quot;</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataset_name</span></a> <span class="o">=</span> <span class="s2">&quot;fastmri_knee_singlecoil&quot;</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_size</span></a> <span class="o">=</span> <span class="mi">128</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_size</span></a><span class="p">)])</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataset_name</span></a><span class="p">,</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ORIGINAL_DATA_DIR</span></a><span class="p">,</span> <span class="n">transform</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataset_name</span></a><span class="p">,</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ORIGINAL_DATA_DIR</span></a><span class="p">,</span> <span class="n">transform</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading datasets/fastmri_knee_singlecoil.pt

  0%|          | 0.00/399M [00:00&lt;?, ?iB/s]
  0%|          | 1.24M/399M [00:00&lt;00:37, 10.5MiB/s]
  1%|          | 2.29M/399M [00:00&lt;00:37, 10.5MiB/s]
  1%|          | 3.34M/399M [00:00&lt;00:37, 10.5MiB/s]
  1%|          | 4.39M/399M [00:00&lt;00:37, 10.4MiB/s]
  1%|▏         | 5.43M/399M [00:00&lt;00:37, 10.4MiB/s]
  2%|▏         | 6.48M/399M [00:00&lt;00:37, 10.4MiB/s]
  2%|▏         | 7.53M/399M [00:00&lt;00:37, 10.4MiB/s]
  2%|▏         | 8.60M/399M [00:00&lt;00:37, 10.5MiB/s]
  2%|▏         | 9.65M/399M [00:00&lt;00:37, 10.5MiB/s]
  3%|▎         | 10.7M/399M [00:01&lt;00:36, 10.6MiB/s]
  3%|▎         | 11.8M/399M [00:01&lt;00:37, 10.4MiB/s]
  3%|▎         | 12.9M/399M [00:01&lt;00:36, 10.6MiB/s]
  3%|▎         | 13.9M/399M [00:01&lt;00:36, 10.6MiB/s]
  4%|▍         | 15.0M/399M [00:01&lt;00:36, 10.5MiB/s]
  4%|▍         | 16.1M/399M [00:01&lt;00:36, 10.5MiB/s]
  4%|▍         | 17.1M/399M [00:01&lt;00:36, 10.4MiB/s]
  5%|▍         | 18.2M/399M [00:01&lt;00:36, 10.4MiB/s]
  5%|▍         | 19.2M/399M [00:01&lt;00:36, 10.4MiB/s]
  5%|▌         | 20.2M/399M [00:01&lt;00:36, 10.4MiB/s]
  5%|▌         | 21.3M/399M [00:02&lt;00:35, 10.6MiB/s]
  6%|▌         | 22.4M/399M [00:02&lt;00:35, 10.6MiB/s]
  6%|▌         | 23.5M/399M [00:02&lt;00:35, 10.6MiB/s]
  6%|▌         | 24.5M/399M [00:02&lt;00:35, 10.6MiB/s]
  6%|▋         | 25.6M/399M [00:02&lt;00:35, 10.5MiB/s]
  7%|▋         | 26.7M/399M [00:02&lt;00:35, 10.4MiB/s]
  7%|▋         | 27.7M/399M [00:02&lt;00:35, 10.4MiB/s]
  7%|▋         | 28.7M/399M [00:02&lt;00:35, 10.3MiB/s]
  7%|▋         | 29.8M/399M [00:02&lt;00:35, 10.3MiB/s]
  8%|▊         | 30.8M/399M [00:02&lt;00:35, 10.3MiB/s]
  8%|▊         | 31.8M/399M [00:03&lt;00:35, 10.3MiB/s]
  8%|▊         | 32.9M/399M [00:03&lt;00:35, 10.2MiB/s]
  9%|▊         | 34.0M/399M [00:03&lt;00:36, 9.92MiB/s]
  9%|▉         | 35.1M/399M [00:03&lt;00:36, 10.1MiB/s]
  9%|▉         | 36.1M/399M [00:03&lt;00:35, 10.1MiB/s]
  9%|▉         | 37.2M/399M [00:03&lt;00:35, 10.3MiB/s]
 10%|▉         | 38.2M/399M [00:03&lt;00:34, 10.4MiB/s]
 10%|▉         | 39.3M/399M [00:03&lt;00:34, 10.4MiB/s]
 10%|█         | 40.4M/399M [00:03&lt;00:34, 10.5MiB/s]
 10%|█         | 41.4M/399M [00:03&lt;00:34, 10.5MiB/s]
 11%|█         | 42.5M/399M [00:04&lt;00:33, 10.5MiB/s]
 11%|█         | 43.5M/399M [00:04&lt;00:33, 10.5MiB/s]
 11%|█         | 44.6M/399M [00:04&lt;00:33, 10.6MiB/s]
 11%|█▏        | 45.7M/399M [00:04&lt;00:33, 10.5MiB/s]
 12%|█▏        | 46.7M/399M [00:04&lt;00:33, 10.5MiB/s]
 12%|█▏        | 47.8M/399M [00:04&lt;00:33, 10.5MiB/s]
 12%|█▏        | 48.8M/399M [00:04&lt;00:33, 10.4MiB/s]
 13%|█▎        | 49.8M/399M [00:04&lt;00:33, 10.3MiB/s]
 13%|█▎        | 50.9M/399M [00:04&lt;00:33, 10.3MiB/s]
 13%|█▎        | 51.9M/399M [00:04&lt;00:33, 10.3MiB/s]
 13%|█▎        | 52.9M/399M [00:05&lt;00:33, 10.3MiB/s]
 14%|█▎        | 54.0M/399M [00:05&lt;00:33, 10.3MiB/s]
 14%|█▍        | 55.0M/399M [00:05&lt;00:33, 10.3MiB/s]
 14%|█▍        | 56.0M/399M [00:05&lt;00:33, 10.2MiB/s]
 14%|█▍        | 57.1M/399M [00:05&lt;00:32, 10.4MiB/s]
 15%|█▍        | 58.1M/399M [00:05&lt;00:32, 10.4MiB/s]
 15%|█▍        | 59.2M/399M [00:05&lt;00:32, 10.3MiB/s]
 15%|█▌        | 60.2M/399M [00:05&lt;00:32, 10.3MiB/s]
 15%|█▌        | 61.3M/399M [00:05&lt;00:32, 10.2MiB/s]
 16%|█▌        | 62.5M/399M [00:05&lt;00:31, 10.7MiB/s]
 16%|█▌        | 63.5M/399M [00:06&lt;00:31, 10.7MiB/s]
 16%|█▌        | 64.6M/399M [00:06&lt;00:31, 10.7MiB/s]
 16%|█▋        | 65.7M/399M [00:06&lt;00:31, 10.6MiB/s]
 17%|█▋        | 66.7M/399M [00:06&lt;00:31, 10.6MiB/s]
 17%|█▋        | 67.8M/399M [00:06&lt;00:31, 10.6MiB/s]
 17%|█▋        | 68.9M/399M [00:06&lt;00:33, 9.97MiB/s]
 18%|█▊        | 69.9M/399M [00:06&lt;00:32, 10.1MiB/s]
 18%|█▊        | 71.0M/399M [00:06&lt;00:32, 10.2MiB/s]
 18%|█▊        | 72.0M/399M [00:06&lt;00:31, 10.2MiB/s]
 18%|█▊        | 73.2M/399M [00:07&lt;00:30, 10.7MiB/s]
 19%|█▊        | 74.3M/399M [00:07&lt;00:30, 10.7MiB/s]
 19%|█▉        | 75.4M/399M [00:07&lt;00:29, 10.8MiB/s]
 19%|█▉        | 76.5M/399M [00:07&lt;00:31, 10.2MiB/s]
 19%|█▉        | 77.5M/399M [00:07&lt;00:31, 10.2MiB/s]
 20%|█▉        | 78.6M/399M [00:07&lt;00:31, 10.3MiB/s]
 20%|█▉        | 79.6M/399M [00:07&lt;00:30, 10.3MiB/s]
 20%|██        | 80.7M/399M [00:07&lt;00:30, 10.4MiB/s]
 21%|██        | 81.7M/399M [00:07&lt;00:30, 10.3MiB/s]
 21%|██        | 82.8M/399M [00:07&lt;00:30, 10.5MiB/s]
 21%|██        | 83.9M/399M [00:08&lt;00:30, 10.5MiB/s]
 21%|██▏       | 84.9M/399M [00:08&lt;00:29, 10.5MiB/s]
 22%|██▏       | 86.0M/399M [00:08&lt;00:29, 10.6MiB/s]
 22%|██▏       | 87.1M/399M [00:08&lt;00:29, 10.6MiB/s]
 22%|██▏       | 88.1M/399M [00:08&lt;00:29, 10.6MiB/s]
 22%|██▏       | 89.2M/399M [00:08&lt;00:29, 10.6MiB/s]
 23%|██▎       | 90.3M/399M [00:08&lt;00:29, 10.6MiB/s]
 23%|██▎       | 91.3M/399M [00:08&lt;00:29, 10.6MiB/s]
 23%|██▎       | 92.4M/399M [00:08&lt;00:29, 10.4MiB/s]
 23%|██▎       | 93.4M/399M [00:08&lt;00:29, 10.4MiB/s]
 24%|██▎       | 94.5M/399M [00:09&lt;00:29, 10.4MiB/s]
 24%|██▍       | 95.5M/399M [00:09&lt;00:29, 10.3MiB/s]
 24%|██▍       | 96.7M/399M [00:09&lt;00:30, 10.1MiB/s]
 25%|██▍       | 97.7M/399M [00:09&lt;00:29, 10.1MiB/s]
 25%|██▍       | 98.8M/399M [00:09&lt;00:29, 10.2MiB/s]
 25%|██▌       | 99.8M/399M [00:09&lt;00:29, 10.2MiB/s]
 25%|██▌       | 101M/399M [00:09&lt;00:28, 10.3MiB/s]
 26%|██▌       | 102M/399M [00:09&lt;00:28, 10.3MiB/s]
 26%|██▌       | 103M/399M [00:09&lt;00:28, 10.3MiB/s]
 26%|██▌       | 104M/399M [00:09&lt;00:28, 10.3MiB/s]
 26%|██▋       | 105M/399M [00:10&lt;00:28, 10.5MiB/s]
 27%|██▋       | 106M/399M [00:10&lt;00:27, 10.5MiB/s]
 27%|██▋       | 107M/399M [00:10&lt;00:28, 10.3MiB/s]
 27%|██▋       | 108M/399M [00:10&lt;00:27, 10.4MiB/s]
 27%|██▋       | 110M/399M [00:10&lt;00:27, 10.3MiB/s]
 28%|██▊       | 111M/399M [00:10&lt;00:27, 10.4MiB/s]
 28%|██▊       | 112M/399M [00:10&lt;00:27, 10.4MiB/s]
 28%|██▊       | 113M/399M [00:10&lt;00:27, 10.3MiB/s]
 29%|██▊       | 114M/399M [00:10&lt;00:27, 10.3MiB/s]
 29%|██▉       | 115M/399M [00:11&lt;00:27, 10.3MiB/s]
 29%|██▉       | 116M/399M [00:11&lt;00:26, 10.9MiB/s]
 29%|██▉       | 117M/399M [00:11&lt;00:25, 10.9MiB/s]
 30%|██▉       | 118M/399M [00:11&lt;00:25, 10.8MiB/s]
 30%|██▉       | 119M/399M [00:11&lt;00:27, 10.1MiB/s]
 30%|███       | 120M/399M [00:11&lt;00:27, 10.2MiB/s]
 30%|███       | 121M/399M [00:11&lt;00:27, 10.2MiB/s]
 31%|███       | 122M/399M [00:11&lt;00:26, 10.3MiB/s]
 31%|███       | 123M/399M [00:11&lt;00:26, 10.3MiB/s]
 31%|███       | 124M/399M [00:11&lt;00:26, 10.4MiB/s]
 31%|███▏      | 125M/399M [00:12&lt;00:26, 10.3MiB/s]
 32%|███▏      | 127M/399M [00:12&lt;00:26, 10.4MiB/s]
 32%|███▏      | 128M/399M [00:12&lt;00:25, 10.6MiB/s]
 32%|███▏      | 129M/399M [00:12&lt;00:25, 10.6MiB/s]
 33%|███▎      | 130M/399M [00:12&lt;00:25, 10.6MiB/s]
 33%|███▎      | 131M/399M [00:12&lt;00:25, 10.7MiB/s]
 33%|███▎      | 132M/399M [00:12&lt;00:25, 10.6MiB/s]
 33%|███▎      | 133M/399M [00:12&lt;00:25, 10.6MiB/s]
 34%|███▎      | 134M/399M [00:12&lt;00:25, 10.5MiB/s]
 34%|███▍      | 135M/399M [00:12&lt;00:25, 10.5MiB/s]
 34%|███▍      | 136M/399M [00:13&lt;00:25, 10.4MiB/s]
 34%|███▍      | 137M/399M [00:13&lt;00:25, 10.4MiB/s]
 35%|███▍      | 138M/399M [00:13&lt;00:25, 10.4MiB/s]
 35%|███▍      | 139M/399M [00:13&lt;00:25, 10.4MiB/s]
 35%|███▌      | 140M/399M [00:13&lt;00:24, 10.5MiB/s]
 35%|███▌      | 141M/399M [00:13&lt;00:24, 10.4MiB/s]
 36%|███▌      | 143M/399M [00:13&lt;00:23, 10.7MiB/s]
 36%|███▌      | 144M/399M [00:13&lt;00:25, 10.0MiB/s]
 36%|███▋      | 145M/399M [00:13&lt;00:25, 10.1MiB/s]
 37%|███▋      | 146M/399M [00:14&lt;00:24, 10.1MiB/s]
 37%|███▋      | 147M/399M [00:14&lt;00:24, 10.2MiB/s]
 37%|███▋      | 148M/399M [00:14&lt;00:24, 10.3MiB/s]
 37%|███▋      | 149M/399M [00:14&lt;00:24, 10.3MiB/s]
 38%|███▊      | 150M/399M [00:14&lt;00:24, 10.3MiB/s]
 38%|███▊      | 151M/399M [00:14&lt;00:23, 10.4MiB/s]
 38%|███▊      | 152M/399M [00:14&lt;00:23, 10.3MiB/s]
 38%|███▊      | 153M/399M [00:14&lt;00:23, 10.4MiB/s]
 39%|███▊      | 154M/399M [00:14&lt;00:23, 10.4MiB/s]
 39%|███▉      | 155M/399M [00:14&lt;00:23, 10.4MiB/s]
 39%|███▉      | 156M/399M [00:15&lt;00:23, 10.3MiB/s]
 39%|███▉      | 157M/399M [00:15&lt;00:23, 10.3MiB/s]
 40%|███▉      | 158M/399M [00:15&lt;00:23, 10.4MiB/s]
 40%|███▉      | 159M/399M [00:15&lt;00:22, 10.4MiB/s]
 40%|████      | 160M/399M [00:15&lt;00:22, 10.5MiB/s]
 41%|████      | 161M/399M [00:15&lt;00:22, 10.4MiB/s]
 41%|████      | 162M/399M [00:15&lt;00:22, 10.4MiB/s]
 41%|████      | 164M/399M [00:15&lt;00:22, 10.5MiB/s]
 41%|████▏     | 165M/399M [00:15&lt;00:22, 10.4MiB/s]
 42%|████▏     | 166M/399M [00:15&lt;00:22, 10.4MiB/s]
 42%|████▏     | 167M/399M [00:16&lt;00:22, 10.4MiB/s]
 42%|████▏     | 168M/399M [00:16&lt;00:21, 10.5MiB/s]
 42%|████▏     | 169M/399M [00:16&lt;00:22, 10.4MiB/s]
 43%|████▎     | 170M/399M [00:16&lt;00:22, 9.99MiB/s]
 43%|████▎     | 171M/399M [00:16&lt;00:21, 10.5MiB/s]
 43%|████▎     | 172M/399M [00:16&lt;00:21, 10.6MiB/s]
 44%|████▎     | 174M/399M [00:16&lt;00:21, 10.6MiB/s]
 44%|████▍     | 175M/399M [00:16&lt;00:21, 10.6MiB/s]
 44%|████▍     | 176M/399M [00:16&lt;00:21, 10.5MiB/s]
 44%|████▍     | 177M/399M [00:16&lt;00:21, 10.5MiB/s]
 45%|████▍     | 178M/399M [00:17&lt;00:20, 10.5MiB/s]
 45%|████▍     | 179M/399M [00:17&lt;00:20, 10.5MiB/s]
 45%|████▌     | 180M/399M [00:17&lt;00:20, 10.5MiB/s]
 45%|████▌     | 181M/399M [00:17&lt;00:20, 10.5MiB/s]
 46%|████▌     | 182M/399M [00:17&lt;00:20, 10.4MiB/s]
 46%|████▌     | 183M/399M [00:17&lt;00:20, 10.5MiB/s]
 46%|████▌     | 184M/399M [00:17&lt;00:20, 10.5MiB/s]
 46%|████▋     | 185M/399M [00:17&lt;00:20, 10.4MiB/s]
 47%|████▋     | 186M/399M [00:17&lt;00:20, 10.4MiB/s]
 47%|████▋     | 187M/399M [00:17&lt;00:20, 10.4MiB/s]
 47%|████▋     | 188M/399M [00:18&lt;00:19, 10.5MiB/s]
 48%|████▊     | 189M/399M [00:18&lt;00:19, 10.5MiB/s]
 48%|████▊     | 190M/399M [00:18&lt;00:19, 10.4MiB/s]
 48%|████▊     | 191M/399M [00:18&lt;00:19, 10.4MiB/s]
 48%|████▊     | 193M/399M [00:18&lt;00:19, 10.4MiB/s]
 49%|████▊     | 194M/399M [00:18&lt;00:19, 10.4MiB/s]
 49%|████▉     | 195M/399M [00:18&lt;00:19, 10.4MiB/s]
 49%|████▉     | 196M/399M [00:18&lt;00:20, 10.1MiB/s]
 49%|████▉     | 197M/399M [00:18&lt;00:19, 10.2MiB/s]
 50%|████▉     | 198M/399M [00:19&lt;00:19, 10.3MiB/s]
 50%|████▉     | 199M/399M [00:19&lt;00:19, 10.4MiB/s]
 50%|█████     | 200M/399M [00:19&lt;00:19, 10.4MiB/s]
 50%|█████     | 201M/399M [00:19&lt;00:18, 10.4MiB/s]
 51%|█████     | 202M/399M [00:19&lt;00:18, 10.5MiB/s]
 51%|█████     | 203M/399M [00:19&lt;00:18, 10.5MiB/s]
 51%|█████     | 204M/399M [00:19&lt;00:18, 10.5MiB/s]
 51%|█████▏    | 205M/399M [00:19&lt;00:18, 10.5MiB/s]
 52%|█████▏    | 206M/399M [00:19&lt;00:18, 10.4MiB/s]
 52%|█████▏    | 207M/399M [00:19&lt;00:17, 10.8MiB/s]
 52%|█████▏    | 209M/399M [00:20&lt;00:17, 10.8MiB/s]
 53%|█████▎    | 210M/399M [00:20&lt;00:17, 10.8MiB/s]
 53%|█████▎    | 211M/399M [00:20&lt;00:18, 10.0MiB/s]
 53%|█████▎    | 212M/399M [00:20&lt;00:18, 10.0MiB/s]
 53%|█████▎    | 213M/399M [00:20&lt;00:18, 10.2MiB/s]
 54%|█████▎    | 214M/399M [00:20&lt;00:17, 10.3MiB/s]
 54%|█████▍    | 215M/399M [00:20&lt;00:17, 10.3MiB/s]
 54%|█████▍    | 216M/399M [00:20&lt;00:17, 10.4MiB/s]
 54%|█████▍    | 217M/399M [00:20&lt;00:17, 10.3MiB/s]
 55%|█████▍    | 218M/399M [00:20&lt;00:17, 10.3MiB/s]
 55%|█████▍    | 219M/399M [00:21&lt;00:17, 10.3MiB/s]
 55%|█████▌    | 220M/399M [00:21&lt;00:17, 10.4MiB/s]
 55%|█████▌    | 221M/399M [00:21&lt;00:17, 10.3MiB/s]
 56%|█████▌    | 222M/399M [00:21&lt;00:16, 10.4MiB/s]
 56%|█████▌    | 223M/399M [00:21&lt;00:16, 10.4MiB/s]
 56%|█████▋    | 224M/399M [00:21&lt;00:17, 10.1MiB/s]
 57%|█████▋    | 226M/399M [00:21&lt;00:16, 10.5MiB/s]
 57%|█████▋    | 227M/399M [00:21&lt;00:16, 10.5MiB/s]
 57%|█████▋    | 228M/399M [00:21&lt;00:16, 10.4MiB/s]
 57%|█████▋    | 229M/399M [00:21&lt;00:16, 10.5MiB/s]
 58%|█████▊    | 230M/399M [00:22&lt;00:16, 10.5MiB/s]
 58%|█████▊    | 231M/399M [00:22&lt;00:16, 10.4MiB/s]
 58%|█████▊    | 232M/399M [00:22&lt;00:15, 10.5MiB/s]
 58%|█████▊    | 233M/399M [00:22&lt;00:15, 10.5MiB/s]
 59%|█████▊    | 234M/399M [00:22&lt;00:15, 10.6MiB/s]
 59%|█████▉    | 235M/399M [00:22&lt;00:15, 10.5MiB/s]
 59%|█████▉    | 236M/399M [00:22&lt;00:15, 10.5MiB/s]
 60%|█████▉    | 237M/399M [00:22&lt;00:15, 10.5MiB/s]
 60%|█████▉    | 238M/399M [00:22&lt;00:15, 10.4MiB/s]
 60%|██████    | 239M/399M [00:22&lt;00:15, 10.6MiB/s]
 60%|██████    | 240M/399M [00:23&lt;00:14, 10.6MiB/s]
 61%|██████    | 242M/399M [00:23&lt;00:14, 10.6MiB/s]
 61%|██████    | 243M/399M [00:23&lt;00:14, 10.5MiB/s]
 61%|██████    | 244M/399M [00:23&lt;00:14, 10.5MiB/s]
 61%|██████▏   | 245M/399M [00:23&lt;00:14, 10.4MiB/s]
 62%|██████▏   | 246M/399M [00:23&lt;00:15, 10.0MiB/s]
 62%|██████▏   | 247M/399M [00:23&lt;00:14, 10.2MiB/s]
 62%|██████▏   | 248M/399M [00:23&lt;00:14, 10.2MiB/s]
 62%|██████▏   | 249M/399M [00:23&lt;00:14, 10.3MiB/s]
 63%|██████▎   | 250M/399M [00:24&lt;00:14, 10.3MiB/s]
 63%|██████▎   | 251M/399M [00:24&lt;00:14, 10.3MiB/s]
 63%|██████▎   | 252M/399M [00:24&lt;00:14, 9.93MiB/s]
 64%|██████▎   | 253M/399M [00:24&lt;00:14, 10.1MiB/s]
 64%|██████▍   | 255M/399M [00:24&lt;00:13, 10.5MiB/s]
 64%|██████▍   | 256M/399M [00:24&lt;00:13, 10.6MiB/s]
 64%|██████▍   | 257M/399M [00:24&lt;00:13, 10.8MiB/s]
 65%|██████▍   | 258M/399M [00:24&lt;00:13, 10.7MiB/s]
 65%|██████▌   | 259M/399M [00:24&lt;00:12, 10.8MiB/s]
 65%|██████▌   | 260M/399M [00:24&lt;00:12, 10.8MiB/s]
 66%|██████▌   | 261M/399M [00:25&lt;00:13, 10.2MiB/s]
 66%|██████▌   | 262M/399M [00:25&lt;00:13, 10.2MiB/s]
 66%|██████▌   | 263M/399M [00:25&lt;00:13, 10.3MiB/s]
 66%|██████▋   | 264M/399M [00:25&lt;00:13, 10.3MiB/s]
 67%|██████▋   | 265M/399M [00:25&lt;00:13, 10.2MiB/s]
 67%|██████▋   | 267M/399M [00:25&lt;00:12, 10.4MiB/s]
 67%|██████▋   | 268M/399M [00:25&lt;00:12, 10.4MiB/s]
 67%|██████▋   | 269M/399M [00:25&lt;00:12, 10.4MiB/s]
 68%|██████▊   | 270M/399M [00:25&lt;00:12, 10.4MiB/s]
 68%|██████▊   | 271M/399M [00:26&lt;00:12, 10.3MiB/s]
 68%|██████▊   | 272M/399M [00:26&lt;00:12, 10.4MiB/s]
 69%|██████▊   | 273M/399M [00:26&lt;00:12, 10.4MiB/s]
 69%|██████▉   | 274M/399M [00:26&lt;00:11, 10.5MiB/s]
 69%|██████▉   | 275M/399M [00:26&lt;00:11, 10.5MiB/s]
 69%|██████▉   | 276M/399M [00:26&lt;00:11, 10.5MiB/s]
 70%|██████▉   | 277M/399M [00:26&lt;00:11, 10.5MiB/s]
 70%|██████▉   | 278M/399M [00:26&lt;00:11, 10.5MiB/s]
 70%|███████   | 279M/399M [00:26&lt;00:11, 10.5MiB/s]
 70%|███████   | 280M/399M [00:26&lt;00:11, 10.4MiB/s]
 71%|███████   | 282M/399M [00:27&lt;00:11, 10.4MiB/s]
 71%|███████   | 283M/399M [00:27&lt;00:11, 10.4MiB/s]
 71%|███████   | 284M/399M [00:27&lt;00:11, 10.4MiB/s]
 71%|███████▏  | 285M/399M [00:27&lt;00:11, 10.4MiB/s]
 72%|███████▏  | 286M/399M [00:27&lt;00:10, 10.4MiB/s]
 72%|███████▏  | 287M/399M [00:27&lt;00:10, 10.4MiB/s]
 72%|███████▏  | 288M/399M [00:27&lt;00:10, 10.4MiB/s]
 72%|███████▏  | 289M/399M [00:27&lt;00:10, 10.4MiB/s]
 73%|███████▎  | 290M/399M [00:27&lt;00:10, 10.4MiB/s]
 73%|███████▎  | 291M/399M [00:27&lt;00:10, 10.4MiB/s]
 73%|███████▎  | 292M/399M [00:28&lt;00:10, 10.4MiB/s]
 74%|███████▎  | 293M/399M [00:28&lt;00:10, 10.2MiB/s]
 74%|███████▍  | 294M/399M [00:28&lt;00:09, 10.5MiB/s]
 74%|███████▍  | 295M/399M [00:28&lt;00:09, 10.5MiB/s]
 74%|███████▍  | 296M/399M [00:28&lt;00:09, 10.4MiB/s]
 75%|███████▍  | 297M/399M [00:28&lt;00:09, 10.6MiB/s]
 75%|███████▍  | 299M/399M [00:28&lt;00:09, 10.5MiB/s]
 75%|███████▌  | 300M/399M [00:28&lt;00:09, 10.5MiB/s]
 75%|███████▌  | 301M/399M [00:28&lt;00:09, 10.5MiB/s]
 76%|███████▌  | 302M/399M [00:28&lt;00:09, 10.5MiB/s]
 76%|███████▌  | 303M/399M [00:29&lt;00:09, 10.4MiB/s]
 76%|███████▌  | 304M/399M [00:29&lt;00:09, 10.4MiB/s]
 77%|███████▋  | 305M/399M [00:29&lt;00:08, 10.6MiB/s]
 77%|███████▋  | 306M/399M [00:29&lt;00:08, 10.7MiB/s]
 77%|███████▋  | 307M/399M [00:29&lt;00:08, 10.6MiB/s]
 77%|███████▋  | 308M/399M [00:29&lt;00:08, 10.6MiB/s]
 78%|███████▊  | 309M/399M [00:29&lt;00:08, 10.2MiB/s]
 78%|███████▊  | 310M/399M [00:29&lt;00:08, 10.2MiB/s]
 78%|███████▊  | 311M/399M [00:29&lt;00:08, 10.2MiB/s]
 78%|███████▊  | 312M/399M [00:30&lt;00:08, 10.5MiB/s]
 79%|███████▊  | 314M/399M [00:30&lt;00:07, 10.9MiB/s]
 79%|███████▉  | 315M/399M [00:30&lt;00:07, 10.9MiB/s]
 79%|███████▉  | 316M/399M [00:30&lt;00:08, 10.2MiB/s]
 80%|███████▉  | 317M/399M [00:30&lt;00:07, 10.2MiB/s]
 80%|███████▉  | 318M/399M [00:30&lt;00:07, 10.2MiB/s]
 80%|████████  | 319M/399M [00:30&lt;00:07, 10.3MiB/s]
 80%|████████  | 320M/399M [00:30&lt;00:07, 10.4MiB/s]
 81%|████████  | 321M/399M [00:30&lt;00:07, 10.5MiB/s]
 81%|████████  | 322M/399M [00:30&lt;00:07, 10.5MiB/s]
 81%|████████  | 323M/399M [00:31&lt;00:07, 10.5MiB/s]
 81%|████████▏ | 324M/399M [00:31&lt;00:07, 10.4MiB/s]
 82%|████████▏ | 325M/399M [00:31&lt;00:06, 10.5MiB/s]
 82%|████████▏ | 326M/399M [00:31&lt;00:06, 10.5MiB/s]
 82%|████████▏ | 327M/399M [00:31&lt;00:06, 10.5MiB/s]
 82%|████████▏ | 328M/399M [00:31&lt;00:06, 10.5MiB/s]
 83%|████████▎ | 330M/399M [00:31&lt;00:06, 10.5MiB/s]
 83%|████████▎ | 331M/399M [00:31&lt;00:06, 10.5MiB/s]
 83%|████████▎ | 332M/399M [00:31&lt;00:06, 10.7MiB/s]
 83%|████████▎ | 333M/399M [00:31&lt;00:06, 10.7MiB/s]
 84%|████████▍ | 334M/399M [00:32&lt;00:06, 10.6MiB/s]
 84%|████████▍ | 335M/399M [00:32&lt;00:05, 10.6MiB/s]
 84%|████████▍ | 336M/399M [00:32&lt;00:05, 10.7MiB/s]
 85%|████████▍ | 337M/399M [00:32&lt;00:05, 10.7MiB/s]
 85%|████████▍ | 338M/399M [00:32&lt;00:06, 9.96MiB/s]
 85%|████████▌ | 339M/399M [00:32&lt;00:05, 10.1MiB/s]
 85%|████████▌ | 340M/399M [00:32&lt;00:05, 10.4MiB/s]
 86%|████████▌ | 341M/399M [00:32&lt;00:05, 10.4MiB/s]
 86%|████████▌ | 342M/399M [00:32&lt;00:05, 10.4MiB/s]
 86%|████████▌ | 343M/399M [00:32&lt;00:05, 10.4MiB/s]
 86%|████████▋ | 344M/399M [00:33&lt;00:05, 10.4MiB/s]
 87%|████████▋ | 345M/399M [00:33&lt;00:05, 10.3MiB/s]
 87%|████████▋ | 347M/399M [00:33&lt;00:05, 10.3MiB/s]
 87%|████████▋ | 348M/399M [00:33&lt;00:04, 10.5MiB/s]
 87%|████████▋ | 349M/399M [00:33&lt;00:04, 10.5MiB/s]
 88%|████████▊ | 350M/399M [00:33&lt;00:04, 10.4MiB/s]
 88%|████████▊ | 351M/399M [00:33&lt;00:04, 10.4MiB/s]
 88%|████████▊ | 352M/399M [00:33&lt;00:04, 10.4MiB/s]
 89%|████████▊ | 353M/399M [00:33&lt;00:04, 10.8MiB/s]
 89%|████████▉ | 354M/399M [00:34&lt;00:04, 10.1MiB/s]
 89%|████████▉ | 355M/399M [00:34&lt;00:04, 10.2MiB/s]
 89%|████████▉ | 356M/399M [00:34&lt;00:04, 10.3MiB/s]
 90%|████████▉ | 357M/399M [00:34&lt;00:03, 10.4MiB/s]
 90%|████████▉ | 358M/399M [00:34&lt;00:03, 10.4MiB/s]
 90%|█████████ | 359M/399M [00:34&lt;00:03, 10.4MiB/s]
 90%|█████████ | 360M/399M [00:34&lt;00:03, 10.4MiB/s]
 91%|█████████ | 361M/399M [00:34&lt;00:03, 10.4MiB/s]
 91%|█████████ | 362M/399M [00:34&lt;00:03, 10.2MiB/s]
 91%|█████████▏| 364M/399M [00:34&lt;00:03, 10.4MiB/s]
 92%|█████████▏| 365M/399M [00:35&lt;00:03, 10.5MiB/s]
 92%|█████████▏| 366M/399M [00:35&lt;00:03, 10.5MiB/s]
 92%|█████████▏| 367M/399M [00:35&lt;00:03, 10.5MiB/s]
 92%|█████████▏| 368M/399M [00:35&lt;00:02, 10.5MiB/s]
 93%|█████████▎| 369M/399M [00:35&lt;00:02, 10.3MiB/s]
 93%|█████████▎| 370M/399M [00:35&lt;00:02, 10.4MiB/s]
 93%|█████████▎| 371M/399M [00:35&lt;00:02, 10.5MiB/s]
 93%|█████████▎| 372M/399M [00:35&lt;00:02, 10.4MiB/s]
 94%|█████████▎| 374M/399M [00:35&lt;00:02, 10.5MiB/s]
 94%|█████████▍| 375M/399M [00:35&lt;00:02, 10.5MiB/s]
 94%|█████████▍| 376M/399M [00:36&lt;00:02, 10.4MiB/s]
 95%|█████████▍| 377M/399M [00:36&lt;00:02, 10.6MiB/s]
 95%|█████████▍| 378M/399M [00:36&lt;00:01, 10.5MiB/s]
 95%|█████████▌| 379M/399M [00:36&lt;00:01, 11.0MiB/s]
 95%|█████████▌| 380M/399M [00:36&lt;00:01, 10.2MiB/s]
 96%|█████████▌| 381M/399M [00:36&lt;00:01, 10.3MiB/s]
 96%|█████████▌| 382M/399M [00:36&lt;00:01, 10.3MiB/s]
 96%|█████████▌| 383M/399M [00:36&lt;00:01, 10.6MiB/s]
 96%|█████████▋| 384M/399M [00:36&lt;00:01, 10.7MiB/s]
 97%|█████████▋| 385M/399M [00:36&lt;00:01, 10.7MiB/s]
 97%|█████████▋| 387M/399M [00:37&lt;00:01, 10.7MiB/s]
 97%|█████████▋| 388M/399M [00:37&lt;00:01, 10.7MiB/s]
 98%|█████████▊| 389M/399M [00:37&lt;00:00, 10.0MiB/s]
 98%|█████████▊| 390M/399M [00:37&lt;00:00, 9.96MiB/s]
 98%|█████████▊| 391M/399M [00:37&lt;00:00, 10.3MiB/s]
 98%|█████████▊| 392M/399M [00:37&lt;00:00, 10.4MiB/s]
 99%|█████████▊| 393M/399M [00:37&lt;00:00, 10.4MiB/s]
 99%|█████████▉| 394M/399M [00:37&lt;00:00, 10.4MiB/s]
 99%|█████████▉| 395M/399M [00:37&lt;00:00, 10.4MiB/s]
 99%|█████████▉| 396M/399M [00:38&lt;00:00, 10.4MiB/s]
100%|█████████▉| 397M/399M [00:38&lt;00:00, 10.6MiB/s]
100%|█████████▉| 398M/399M [00:38&lt;00:00, 10.6MiB/s]
100%|██████████| 399M/399M [00:38&lt;00:00, 10.4MiB/s]
/home/runner/work/deepinv/deepinv/deepinv/utils/demo.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don&#39;t have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  x = torch.load(str(root_dir) + &quot;.pt&quot;)
</pre></div>
</div>
</section>
<section id="generate-a-dataset-of-knee-images-and-load-it">
<h2>Generate a dataset of knee images and load it.<a class="headerlink" href="#generate-a-dataset-of-knee-images-and-load-it" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask</span></a> <span class="o">=</span> <span class="n">load_degradation</span><span class="p">(</span><span class="s2">&quot;mri_mask_128x128.npy&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ORIGINAL_DATA_DIR</span></a><span class="p">)</span>

<span class="c1"># defined physics</span>
<span class="n">physics</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">physics</span><span class="o">.</span><span class="n">MRI</span></a><span class="p">(</span><a href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask</span></a><span class="o">=</span><a href="http://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask</span></a><span class="p">,</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>

<span class="c1"># Use parallel dataloader if using a GPU to fasten training,</span>
<span class="c1"># otherwise, as all computes are on CPU, use synchronous data loading.</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a> <span class="o">=</span> <span class="mi">4</span> <span class="k">if</span> <a href="http://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mi">0</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_images_max</span></a> <span class="o">=</span> <span class="p">(</span>
    <span class="mi">900</span> <span class="k">if</span> <a href="http://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mi">5</span>
<span class="p">)</span>  <span class="c1"># number of images used for training</span>
<span class="c1"># (the dataset has up to 973 images, however here we use only 900)</span>

<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">my_dataset_name</span></a> <span class="o">=</span> <span class="s2">&quot;demo_equivariant_imaging&quot;</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">measurement_dir</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DATA_DIR</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataset_name</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">operation</span></a>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">deepinv_datasets_path</span></a> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">generate_dataset</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span>
    <span class="n">physics</span><span class="o">=</span><span class="n">physics</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">,</span>
    <span class="n">save_dir</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">measurement_dir</span></a><span class="p">,</span>
    <span class="n">train_datapoints</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_images_max</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="p">,</span>
    <span class="n">dataset_filename</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">my_dataset_name</span></a><span class="p">),</span>
<span class="p">)</span>

<span class="n">train_dataset</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">HDF5Dataset</span></a><span class="p">(</span><span class="n">path</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">deepinv_datasets_path</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">HDF5Dataset</span></a><span class="p">(</span><span class="n">path</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">deepinv_datasets_path</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>mri_mask_128x128.npy degradation downloaded in datasets
Dataset has been saved in measurements/fastmri_knee_singlecoil/MRI
</pre></div>
</div>
</section>
<section id="set-up-the-reconstruction-network">
<h2>Set up the reconstruction network<a class="headerlink" href="#set-up-the-reconstruction-network" title="Link to this heading"></a></h2>
<p>As a reconstruction network, we use an unrolled network (half-quadratic splitting)
with a trainable denoising prior based on the DnCNN architecture as an example
of a model-based deep learning architecture from <a class="reference external" href="https://ieeexplore.ieee.org/document/8434321">MoDL</a>.
See <a class="reference internal" href="../../stubs/deepinv.utils.demo.demo_mri_model.html#deepinv.utils.demo.demo_mri_model" title="deepinv.utils.demo.demo_mri_model"><code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.utils.demo.demo_mri_model()</span></code></a> for details.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">demo_mri_model</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="set-up-the-training-parameters">
<h2>Set up the training parameters<a class="headerlink" href="#set-up-the-training-parameters" title="Link to this heading"></a></h2>
<p>We choose a self-supervised training scheme with two losses: the measurement consistency loss (MC)
and the equivariant imaging loss (EI).
The EI loss requires a group of transformations to be defined. The forward model <a class="reference external" href="https://www.jmlr.org/papers/v24/22-0315.html">should not be equivariant to
these transformations</a>.
Here we use the group of 4 rotations of 90 degrees, as the accelerated MRI acquisition is
not equivariant to rotations (while it is equivariant to translations).</p>
<p>See <a class="reference internal" href="../../deepinv.transform.html#transform"><span class="std std-ref">docs</span></a> for full list of available transforms.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We use a pretrained model to reduce training time. You can get the same results by training from scratch
for 150 epochs.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># choose training epochs</span>
<a href="https://docs.python.org/3.4/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learning_rate</span></a> <span class="o">=</span> <span class="mf">5e-4</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_size</span></a> <span class="o">=</span> <span class="mi">16</span> <span class="k">if</span> <a href="http://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mi">1</span>

<span class="c1"># choose self-supervised training losses</span>
<span class="c1"># generates 4 random rotations per image in the batch</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">losses</span></a> <span class="o">=</span> <span class="p">[</span><a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">MCLoss</span></a><span class="p">(),</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">EILoss</span></a><span class="p">(</span><a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">Rotate</span></a><span class="p">(</span><span class="n">n_trans</span><span class="o">=</span><span class="mi">4</span><span class="p">))]</span>

<span class="c1"># choose optimizer and scheduler</span>
<a href="http://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span></a> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learning_rate</span></a><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span>
<a href="http://pytorch.org/docs/2.0/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR" title="torch.optim.lr_scheduler.StepLR" class="sphx-glr-backref-module-torch-optim-lr_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scheduler</span></a> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR" title="torch.optim.lr_scheduler.StepLR" class="sphx-glr-backref-module-torch-optim-lr_scheduler sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span></a><span class="p">(</span><a href="http://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span></a><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># start with a pretrained model to reduce training time</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">file_name</span></a> <span class="o">=</span> <span class="s2">&quot;new_demo_ei_ckp_150_v3.pth&quot;</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">url</span></a> <span class="o">=</span> <span class="n">get_weights_url</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;demo&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">file_name</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">file_name</span></a><span class="p">)</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/hub.html#torch.hub.load_state_dict_from_url" title="torch.hub.load_state_dict_from_url" class="sphx-glr-backref-module-torch-hub sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load_state_dict_from_url</span></a><span class="p">(</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">url</span></a><span class="p">,</span>
    <span class="n">map_location</span><span class="o">=</span><span class="k">lambda</span> <span class="n">storage</span><span class="p">,</span> <span class="n">loc</span><span class="p">:</span> <span class="n">storage</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">file_name</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">file_name</span></a><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># load a checkpoint to reduce training time</span>
<a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">])</span>
<a href="http://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam.load_state_dict" title="torch.optim.Adam.load_state_dict" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">])</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://huggingface.co/deepinv/demo/resolve/main/new_demo_ei_ckp_150_v3.pth?download=true&quot; to /home/runner/.cache/torch/hub/checkpoints/new_demo_ei_ckp_150_v3.pth

  0%|          | 0.00/2.17M [00:00&lt;?, ?B/s]
 29%|██▊       | 640k/2.17M [00:00&lt;00:00, 5.38MB/s]
 57%|█████▋    | 1.25M/2.17M [00:00&lt;00:00, 5.27MB/s]
 86%|████████▌ | 1.88M/2.17M [00:00&lt;00:00, 5.04MB/s]
100%|██████████| 2.17M/2.17M [00:00&lt;00:00, 5.05MB/s]
</pre></div>
</div>
</section>
<section id="train-the-network">
<h2>Train the network<a class="headerlink" href="#train-the-network" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># print training information</span>
<a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># plot curves and images in Weight&amp;Bias</span>

<a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_size</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_size</span></a><span class="p">,</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a><span class="p">(</span>
    <span class="n">test_dataset</span><span class="p">,</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_size</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_size</span></a><span class="p">,</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="c1"># Initialize the trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">physics</span><span class="o">=</span><span class="n">physics</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">,</span>
    <a href="http://pytorch.org/docs/2.0/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR" title="torch.optim.lr_scheduler.StepLR" class="sphx-glr-backref-module-torch-optim-lr_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scheduler</span></a><span class="o">=</span><a href="http://pytorch.org/docs/2.0/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR" title="torch.optim.lr_scheduler.StepLR" class="sphx-glr-backref-module-torch-optim-lr_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scheduler</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">losses</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">losses</span></a><span class="p">,</span>
    <a href="http://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span></a><span class="o">=</span><a href="http://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span></a><span class="p">,</span>
    <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a><span class="o">=</span><a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a><span class="p">,</span>
    <span class="n">plot_images</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">,</span>
    <span class="n">save_path</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CKPT_DIR</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">operation</span></a><span class="p">),</span>
    <a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a><span class="p">,</span>
    <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># disable progress bar for better vis in sphinx gallery.</span>
    <span class="n">ckp_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_demo_equivariant_imaging_001.png" srcset="../../_images/sphx_glr_demo_equivariant_imaging_001.png" alt="Ground truth, Measurement, Reconstruction" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>The model has 187019 trainable parameters
Train epoch 0: MCLoss=0.0, EILoss=0.0, TotalLoss=0.0, PSNR=37.645
</pre></div>
</div>
</section>
<section id="test-the-network">
<h2>Test the network<a class="headerlink" href="#test-the-network" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_demo_equivariant_imaging_002.png" srcset="../../_images/sphx_glr_demo_equivariant_imaging_002.png" alt="Ground truth, Measurement, No learning, Reconstruction" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Eval epoch 0: PSNR=38.288, PSNR no learning=29.389
Test results:
PSNR no learning: 29.389 +- 3.411
PSNR: 38.288 +- 2.265

{&#39;PSNR no learning&#39;: np.float64(29.38880230629281), &#39;PSNR no learning_std&#39;: np.float64(3.411393798566601), &#39;PSNR&#39;: np.float64(38.28786186322774), &#39;PSNR_std&#39;: np.float64(2.2652720747247512)}
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 58.488 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-self-supervised-learning-demo-equivariant-imaging-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/fff43dcb7e01ba08f91d580209308dce/demo_equivariant_imaging.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">demo_equivariant_imaging.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/cc2dd3ba2cedc98abbfca9b6e4a8dd51/demo_equivariant_imaging.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">demo_equivariant_imaging.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/b313b423aa792cc8a70bf9aea60f7d63/demo_equivariant_imaging.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">demo_equivariant_imaging.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="demo_n2n_denoising.html" class="btn btn-neutral float-left" title="Self-supervised denoising with the Neighbor2Neighbor loss." accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="demo_multioperator_imaging.html" class="btn btn-neutral float-right" title="Self-supervised learning from incomplete measurements of multiple operators." accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, DeepInv.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEKFKYSGR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NSEKFKYSGR', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>