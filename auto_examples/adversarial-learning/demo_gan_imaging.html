

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Imaging inverse problems with adversarial networks &mdash; deepinverse 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
    <link rel="shortcut icon" href="../../_static/logo.ico"/>
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=2709fde1"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=35a8b989"></script>
      <script>window.MathJax = {"tex": {"equationNumbers": {"autoNumber": "AMS", "useLabelIds": true}, "macros": {"forw": ["{A\\left({#1}\\right)}", 1], "noise": ["{N\\left({#1}\\right)}", 1], "inverse": ["{R\\left({#1}\\right)}", 1], "inversef": ["{R\\left({#1},{#2}\\right)}", 2], "reg": ["{g_\\sigma\\left({#1}\\right)}", 1], "regname": "g_\\sigma", "sensor": ["{\\eta\\left({#1}\\right)}", 1], "datafid": ["{f\\left({#1},{#2}\\right)}", 2], "datafidname": "f", "distance": ["{d\\left({#1},{#2}\\right)}", 2], "distancename": "d", "denoiser": ["{\\operatorname{D}_{{#2}}\\left({#1}\\right)}", 2], "denoisername": "\\operatorname{D}_{\\sigma}", "xset": "\\mathcal{X}", "yset": "\\mathcal{Y}", "group": "\\mathcal{G}", "metric": ["{d\\left({#1},{#2}\\right)}", 2], "loss": ["{\\mathcal\\left({#1}\\right)}", 1], "conj": ["{\\overline{#1}^{\\top}}", 1]}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Single photon lidar operator for depth ranging." href="../basics/demo_lidar.html" />
    <link rel="prev" title="Radio interferometric imaging with deepinverse" href="../advanced/demo_ri_basic.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/deepinv_logolarge.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.physics.html">Physics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.loss.html">Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.metric.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.transform.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.denoisers.html">Denoisers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.optim.html">Optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.iterative.html">Iterative Reconstruction (PnP, RED, etc.)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.unfolded.html">Unfolded Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.sampling.html">Diffusion Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.other_models.html">Other Reconstruction Methods</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#advanced">Advanced</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#adversarial-learning">Adversarial Learning</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Imaging inverse problems with adversarial networks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#generate-dataset">Generate dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#define-models">Define models</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conditional-gan-training">Conditional GAN training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#uair-training">UAIR training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#csgm-ambientgan-training">CSGM / AmbientGAN training</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#basics">Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#optimization">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#patch-priors">Patch Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#plug-and-play">Plug-and-Play</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#sampling">Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#self-supervised-learning">Self-Supervised Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#unfolded">Unfolded</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.multigpu.html">Using multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.notation.html">Math Notation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.contributing.html">How to Contribute</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">deepinverse</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Examples</a></li>
      <li class="breadcrumb-item active">Imaging inverse problems with adversarial networks</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/auto_examples/adversarial-learning/demo_gan_imaging.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-adversarial-learning-demo-gan-imaging-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="imaging-inverse-problems-with-adversarial-networks">
<span id="sphx-glr-auto-examples-adversarial-learning-demo-gan-imaging-py"></span><h1>Imaging inverse problems with adversarial networks<a class="headerlink" href="#imaging-inverse-problems-with-adversarial-networks" title="Link to this heading">ÔÉÅ</a></h1>
<p>This example shows you how to train various networks using adversarial
training for deblurring problems. We demonstrate running training and
inference using a conditional GAN (i.e. DeblurGAN), CSGM, AmbientGAN and
UAIR implemented in the library, and how to simply train
your own GAN by using <a class="reference internal" href="../../stubs/deepinv.training.AdversarialTrainer.html#deepinv.training.AdversarialTrainer" title="deepinv.training.AdversarialTrainer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.training.AdversarialTrainer()</span></code></a>. These
examples can also be easily extended to train more complicated GANs such
as CycleGAN.</p>
<p>This example is based on the following papers:</p>
<ul class="simple">
<li><p>Kupyn et al., <a class="reference external" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Kupyn_DeblurGAN_Blind_Motion_CVPR_2018_paper.pdf">DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks</a></p></li>
<li><p>Bora et al., <a class="reference external" href="https://arxiv.org/abs/1703.03208">Compressed Sensing using Generative
Models</a> (CSGM)</p></li>
<li><p>Bora et al., <a class="reference external" href="https://openreview.net/forum?id=Hy7fDog0b">AmbientGAN: Generative models from lossy
measurements</a></p></li>
<li><p>Pajot et al., <a class="reference external" href="https://openreview.net/forum?id=BJg4Z3RqF7">Unsupervised Adversarial Image
Reconstruction</a></p></li>
</ul>
<p>Adversarial networks are characterised by the addition of an adversarial
loss <span class="math notranslate nohighlight">\(\mathcal{L}_\text{adv}\)</span> to the standard reconstruction loss:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}_\text{adv}(x,\hat x;D)=\mathbb{E}_{x\sim p_x}\left[q(D(x))\right]+\mathbb{E}_{\hat x\sim p_{\hat x}}\left[q(1-D(\hat x))\right]\]</div>
<p>where <span class="math notranslate nohighlight">\(D(\cdot)\)</span> is the discriminator model, <span class="math notranslate nohighlight">\(x\)</span> is the
reference image, <span class="math notranslate nohighlight">\(\hat x\)</span> is the estimated reconstruction,
<span class="math notranslate nohighlight">\(q(\cdot)\)</span> is a quality function (e.g <span class="math notranslate nohighlight">\(q(x)=x\)</span> for WGAN).
Training alternates between generator <span class="math notranslate nohighlight">\(G\)</span> and discriminator
<span class="math notranslate nohighlight">\(D\)</span> in a minimax game. When there are no ground truths (i.e.
unsupervised), this may be defined on the measurements <span class="math notranslate nohighlight">\(y\)</span>
instead.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">deepinv</span> <span class="k">as</span> <span class="nn">dinv</span>
<span class="kn">from</span> <span class="nn">deepinv.loss</span> <span class="kn">import</span> <span class="n">adversarial</span>
<span class="kn">from</span> <span class="nn">deepinv.physics.generator</span> <span class="kn">import</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">MotionBlurGenerator</span></a>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a><span class="p">,</span> <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.random_split" title="torch.utils.data.random_split" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-function"><span class="n">random_split</span></a>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">ImageFolder</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">Compose</span><span class="p">,</span> <span class="n">ToTensor</span><span class="p">,</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">CenterCrop</span></a><span class="p">,</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Resize</span></a>
<span class="kn">from</span> <span class="nn">torchvision.datasets.utils</span> <span class="kn">import</span> <span class="n">download_and_extract_archive</span>

<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_freer_gpu</span><span class="p">()</span> <span class="k">if</span> <a href="http://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
</pre></div>
</div>
<section id="generate-dataset">
<h2>Generate dataset<a class="headerlink" href="#generate-dataset" title="Link to this heading">ÔÉÅ</a></h2>
<p>In this example we use the Urban100 dataset resized to 128x128. We apply random
motion blur physics using
<a class="reference internal" href="../../stubs/deepinv.physics.generator.MotionBlurGenerator.html#deepinv.physics.generator.MotionBlurGenerator" title="deepinv.physics.generator.MotionBlurGenerator"><code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.physics.generator.MotionBlurGenerator()</span></code></a>, and save the data
using <a class="reference internal" href="../../stubs/deepinv.datasets.generate_dataset.html#deepinv.datasets.generate_dataset" title="deepinv.datasets.generate_dataset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.datasets.generate_dataset()</span></code></a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">physics</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">physics</span><span class="o">.</span><span class="n">Blur</span></a><span class="p">(</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;circular&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>
<span class="n">blur_generator</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">MotionBlurGenerator</span></a><span class="p">((</span><span class="mi">11</span><span class="p">,</span> <span class="mi">11</span><span class="p">))</span>

<span class="n">dataset</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">Urban100HR</span></a><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;Urban100&quot;</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">Compose</span><span class="p">([</span><span class="n">ToTensor</span><span class="p">(),</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Resize</span></a><span class="p">(</span><span class="mi">256</span><span class="p">),</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">CenterCrop</span></a><span class="p">(</span><span class="mi">128</span><span class="p">)]),</span>
<span class="p">)</span>

<a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.Subset" title="torch.utils.data.Subset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataset</span></a><span class="p">,</span> <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.Subset" title="torch.utils.data.Subset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataset</span></a> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.random_split" title="torch.utils.data.random_split" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-function"><span class="n">random_split</span></a><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">))</span>

<span class="c1"># Generate data pairs x,y offline using a physics generator</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dataset_path</span></a> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">generate_dataset</span><span class="p">(</span>
    <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.Subset" title="torch.utils.data.Subset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataset</span></a><span class="o">=</span><a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.Subset" title="torch.utils.data.Subset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataset</span></a><span class="p">,</span>
    <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.Subset" title="torch.utils.data.Subset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataset</span></a><span class="o">=</span><a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.Subset" title="torch.utils.data.Subset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataset</span></a><span class="p">,</span>
    <span class="n">physics</span><span class="o">=</span><span class="n">physics</span><span class="p">,</span>
    <span class="n">physics_generator</span><span class="o">=</span><span class="n">blur_generator</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">,</span>
    <span class="n">save_dir</span><span class="o">=</span><span class="s2">&quot;Urban100&quot;</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a><span class="p">(</span>
    <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">HDF5Dataset</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dataset_path</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a><span class="p">(</span>
    <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">HDF5Dataset</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dataset_path</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/135388067 [00:00&lt;?, ?it/s]
  9%|‚ñâ         | 11.3M/129M [00:00&lt;00:01, 119MB/s]
 19%|‚ñà‚ñâ        | 24.2M/129M [00:00&lt;00:00, 128MB/s]
 29%|‚ñà‚ñà‚ñâ       | 37.5M/129M [00:00&lt;00:00, 133MB/s]
 40%|‚ñà‚ñà‚ñà‚ñà      | 51.8M/129M [00:00&lt;00:00, 139MB/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 67.3M/129M [00:00&lt;00:00, 148MB/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 81.4M/129M [00:00&lt;00:00, 142MB/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 95.1M/129M [00:00&lt;00:00, 140MB/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 108M/129M [00:00&lt;00:00, 141MB/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 123M/129M [00:00&lt;00:00, 142MB/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129M/129M [00:00&lt;00:00, 140MB/s]

Extracting:   0%|          | 0/101 [00:00&lt;?, ?it/s]
Extracting:  16%|‚ñà‚ñå        | 16/101 [00:00&lt;00:00, 148.66it/s]
Extracting:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/101 [00:00&lt;00:00, 157.66it/s]
Extracting:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 53/101 [00:00&lt;00:00, 173.47it/s]
Extracting:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/101 [00:00&lt;00:00, 161.37it/s]
Extracting:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:00&lt;00:00, 159.30it/s]
Extracting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [00:00&lt;00:00, 159.02it/s]
Dataset has been successfully downloaded.
Dataset has been saved in Urban100
</pre></div>
</div>
</section>
<section id="define-models">
<h2>Define models<a class="headerlink" href="#define-models" title="Link to this heading">ÔÉÅ</a></h2>
<p>We first define reconstruction network (i.e conditional generator) and
discriminator network to use for adversarial training. For demonstration
we use a simple U-Net as the reconstruction network and the
discriminator from <a class="reference external" href="https://arxiv.org/abs/1611.07004">PatchGAN</a>, but
these can be replaced with any architecture e.g transformers, unrolled
etc. Further discriminator models are in <a class="reference internal" href="../../deepinv.denoisers.html#adversarial-networks"><span class="std std-ref">adversarial models</span></a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_models</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">D</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lr_g</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">lr_d</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">):</span>
    <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">UNet</span></a><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">scales</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">circular_padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>

    <span class="k">if</span> <span class="n">D</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">D</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">PatchGANDiscriminator</span></a><span class="p">(</span><span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">adversarial</span><span class="o">.</span><span class="n">AdversarialOptimizer</span><span class="p">(</span>
        <a href="http://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr_g</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">),</span>
        <a href="http://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">D</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr_d</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">adversarial</span><span class="o">.</span><span class="n">AdversarialScheduler</span><span class="p">(</span>
        <a href="http://pytorch.org/docs/2.0/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR" title="torch.optim.lr_scheduler.StepLR" class="sphx-glr-backref-module-torch-optim-lr_scheduler sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span></a><span class="p">(</span><a href="http://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span><span class="o">.</span><span class="n">G</span></a><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">),</span>
        <a href="http://pytorch.org/docs/2.0/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR" title="torch.optim.lr_scheduler.StepLR" class="sphx-glr-backref-module-torch-optim-lr_scheduler sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span></a><span class="p">(</span><a href="http://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span><span class="o">.</span><span class="n">D</span></a><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span>
</pre></div>
</div>
</section>
<section id="conditional-gan-training">
<h2>Conditional GAN training<a class="headerlink" href="#conditional-gan-training" title="Link to this heading">ÔÉÅ</a></h2>
<p>Conditional GANs (Kupyn et al., <a class="reference external" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Kupyn_DeblurGAN_Blind_Motion_CVPR_2018_paper.pdf">DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks</a>)
are a type of GAN where the generator is conditioned on a label or input. In the context of imaging,
this can be used to generate images from a given measurement. In this example, we use a simple U-Net as the generator
and a PatchGAN discriminator. The forward pass of the generator is given by:</p>
<p><strong>Conditional GAN</strong> forward pass:</p>
<div class="math notranslate nohighlight">
\[\hat x = G(y)\]</div>
<p><strong>Conditional GAN</strong> loss:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}=\mathcal{L}_\text{sup}(\hat x, x)+\mathcal{L}_\text{adv}(\hat x, x;D)\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{L}_\text{sup}\)</span> is a supervised loss such as
pixel-wise MSE or VGG Perceptual Loss.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_models</span><span class="p">()</span>
</pre></div>
</div>
<p>We next define pixel-wise and adversarial losses as defined above. We use the
MSE for the supervised pixel-wise metric for simplicity but this can be
easily replaced with a perceptual loss if desired.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">loss_g</span> <span class="o">=</span> <span class="p">[</span>
    <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">SupLoss</span></a><span class="p">(</span><span class="n">metric</span><span class="o">=</span><a href="http://pytorch.org/docs/2.0/generated/torch.nn.MSELoss.html#torch.nn.MSELoss" title="torch.nn.MSELoss" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span></a><span class="p">()),</span>
    <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">adversarial</span><span class="o">.</span><span class="n">SupAdversarialGeneratorLoss</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">),</span>
<span class="p">]</span>
<span class="n">loss_d</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">adversarial</span><span class="o">.</span><span class="n">SupAdversarialDiscriminatorLoss</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>
</pre></div>
</div>
<p>We are now ready to train the networks using <a class="reference internal" href="../../stubs/deepinv.training.AdversarialTrainer.html#deepinv.training.AdversarialTrainer" title="deepinv.training.AdversarialTrainer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.training.AdversarialTrainer()</span></code></a>.
We load the pretrained models that were trained in the exact same way after 50 epochs,
and fine-tune the model for 1 epoch for a quick demo.
You can find the pretrained models on HuggingFace <a class="reference external" href="https://huggingface.co/deepinv/adversarial-demo">https://huggingface.co/deepinv/adversarial-demo</a>.
To train from scratch, simply comment out the model loading code and increase the number of epochs.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/hub.html#torch.hub.load_state_dict_from_url" title="torch.hub.load_state_dict_from_url" class="sphx-glr-backref-module-torch-hub sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load_state_dict_from_url</span></a><span class="p">(</span>
    <span class="n">dinv</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_weights_url</span><span class="p">(</span><span class="s2">&quot;adversarial-demo&quot;</span><span class="p">,</span> <span class="s2">&quot;deblurgan_model.pth&quot;</span><span class="p">),</span>
    <span class="n">map_location</span><span class="o">=</span><span class="k">lambda</span> <span class="n">s</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">s</span><span class="p">,</span>
<span class="p">)</span>

<a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">G</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">])</span>
<a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">D</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;state_dict_D&quot;</span><span class="p">])</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">])</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">AdversarialTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">G</span><span class="p">,</span>
    <span class="n">D</span><span class="o">=</span><span class="n">D</span><span class="p">,</span>
    <span class="n">physics</span><span class="o">=</span><span class="n">physics</span><span class="p">,</span>
    <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a><span class="o">=</span><a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a><span class="p">,</span>
    <span class="n">eval_dataloader</span><span class="o">=</span><a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">losses</span><span class="o">=</span><span class="n">loss_g</span><span class="p">,</span>
    <span class="n">losses_d</span><span class="o">=</span><span class="n">loss_d</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">save_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">,</span>
<span class="p">)</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://huggingface.co/deepinv/adversarial-demo/resolve/main/deblurgan_model.pth?download=true&quot; to /home/runner/.cache/torch/hub/checkpoints/deblurgan_model.pth

  0%|          | 0.00/12.7M [00:00&lt;?, ?B/s]
  9%|‚ñâ         | 1.12M/12.7M [00:00&lt;00:01, 10.6MB/s]
 18%|‚ñà‚ñä        | 2.25M/12.7M [00:00&lt;00:00, 11.1MB/s]
 27%|‚ñà‚ñà‚ñã       | 3.38M/12.7M [00:00&lt;00:00, 10.3MB/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 4.38M/12.7M [00:00&lt;00:00, 10.3MB/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5.38M/12.7M [00:00&lt;00:00, 10.3MB/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6.38M/12.7M [00:00&lt;00:00, 10.3MB/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 7.38M/12.7M [00:00&lt;00:00, 10.4MB/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 8.38M/12.7M [00:00&lt;00:00, 10.3MB/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 9.38M/12.7M [00:00&lt;00:00, 10.4MB/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 10.4M/12.7M [00:01&lt;00:00, 10.4MB/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 11.4M/12.7M [00:01&lt;00:00, 10.4MB/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 12.4M/12.7M [00:01&lt;00:00, 10.4MB/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.7M/12.7M [00:01&lt;00:00, 10.5MB/s]
The model has 444867 trainable parameters
Train epoch 0: SupLoss=0.004, SupAdversarialGeneratorLoss=0.003, TotalLoss=0.006, PSNR=25.826
Eval epoch 0: PSNR=25.339
</pre></div>
</div>
<p>Test the trained model and plot the results. We compare to the pseudo-inverse as a baseline.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">trainer</span><span class="o">.</span><span class="n">plot_images</span></a> <span class="o">=</span> <span class="kc">True</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_demo_gan_imaging_001.png" srcset="../../_images/sphx_glr_demo_gan_imaging_001.png" alt="Ground truth, Measurement, No learning, Reconstruction" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Eval epoch 0: PSNR=25.339, PSNR no learning=22.129
Test results:
PSNR no learning: 22.129 +- 2.703
PSNR: 25.339 +- 3.741

{&#39;PSNR no learning&#39;: np.float64(22.128802490234374), &#39;PSNR no learning_std&#39;: np.float64(2.703303237720839), &#39;PSNR&#39;: np.float64(25.33935546875), &#39;PSNR_std&#39;: np.float64(3.7408121787192714)}
</pre></div>
</div>
</section>
<section id="uair-training">
<h2>UAIR training<a class="headerlink" href="#uair-training" title="Link to this heading">ÔÉÅ</a></h2>
<p>Unsupervised Adversarial Image Reconstruction (UAIR) (Pajot et al.,
<a class="reference external" href="https://openreview.net/forum?id=BJg4Z3RqF7">Unsupervised Adversarial Image Reconstruction</a>)
is a method for solving inverse problems using generative models. In this
example, we use a simple U-Net as the generator and discriminator, and
train using the adversarial loss. The forward pass of the generator is defined as:</p>
<p><strong>UAIR</strong> forward pass:</p>
<div class="math notranslate nohighlight">
\[\hat x = G(y),\]</div>
<p><strong>UAIR</strong> loss:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}=\mathcal{L}_\text{adv}(\hat y, y;D)+\lVert \forw{\inverse{\hat y}}- \hat y\rVert^2_2,\quad\hat y=\forw{\hat x}.\]</div>
<p>We next load the models and construct losses as defined above.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_models</span><span class="p">(</span>
    <span class="n">lr_g</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">lr_d</span><span class="o">=</span><span class="mf">4e-4</span>
<span class="p">)</span>  <span class="c1"># learning rates from original paper</span>

<span class="n">loss_g</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">adversarial</span><span class="o">.</span><span class="n">UAIRGeneratorLoss</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>
<span class="n">loss_d</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">adversarial</span><span class="o">.</span><span class="n">UnsupAdversarialDiscriminatorLoss</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>
</pre></div>
</div>
<p>We are now ready to train the networks using <a class="reference internal" href="../../stubs/deepinv.training.AdversarialTrainer.html#deepinv.training.AdversarialTrainer" title="deepinv.training.AdversarialTrainer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.training.AdversarialTrainer()</span></code></a>.
Like above, we load a pretrained model trained in the exact same way for 50 epochs,
and fine-tune here for a quick demo with 1 epoch.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/hub.html#torch.hub.load_state_dict_from_url" title="torch.hub.load_state_dict_from_url" class="sphx-glr-backref-module-torch-hub sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load_state_dict_from_url</span></a><span class="p">(</span>
    <span class="n">dinv</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_weights_url</span><span class="p">(</span><span class="s2">&quot;adversarial-demo&quot;</span><span class="p">,</span> <span class="s2">&quot;uair_model.pth&quot;</span><span class="p">),</span>
    <span class="n">map_location</span><span class="o">=</span><span class="k">lambda</span> <span class="n">s</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">s</span><span class="p">,</span>
<span class="p">)</span>

<a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">G</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">])</span>
<a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">D</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;state_dict_D&quot;</span><span class="p">])</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">])</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">AdversarialTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">G</span><span class="p">,</span>
    <span class="n">D</span><span class="o">=</span><span class="n">D</span><span class="p">,</span>
    <span class="n">physics</span><span class="o">=</span><span class="n">physics</span><span class="p">,</span>
    <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a><span class="o">=</span><a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a><span class="p">,</span>
    <span class="n">eval_dataloader</span><span class="o">=</span><a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">losses</span><span class="o">=</span><span class="n">loss_g</span><span class="p">,</span>
    <span class="n">losses_d</span><span class="o">=</span><span class="n">loss_d</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">save_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">,</span>
<span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://huggingface.co/deepinv/adversarial-demo/resolve/main/uair_model.pth?download=true&quot; to /home/runner/.cache/torch/hub/checkpoints/uair_model.pth

  0%|          | 0.00/12.7M [00:00&lt;?, ?B/s]
  2%|‚ñè         | 256k/12.7M [00:00&lt;00:08, 1.62MB/s]
  4%|‚ñç         | 512k/12.7M [00:00&lt;00:07, 1.68MB/s]
  6%|‚ñå         | 768k/12.7M [00:00&lt;00:07, 1.76MB/s]
  8%|‚ñä         | 1.00M/12.7M [00:00&lt;00:06, 1.81MB/s]
 10%|‚ñâ         | 1.25M/12.7M [00:00&lt;00:06, 1.92MB/s]
 12%|‚ñà‚ñè        | 1.50M/12.7M [00:00&lt;00:05, 1.96MB/s]
 15%|‚ñà‚ñç        | 1.88M/12.7M [00:00&lt;00:05, 2.20MB/s]
 18%|‚ñà‚ñä        | 2.25M/12.7M [00:01&lt;00:04, 2.50MB/s]
 21%|‚ñà‚ñà        | 2.62M/12.7M [00:01&lt;00:03, 2.77MB/s]
 24%|‚ñà‚ñà‚ñé       | 3.00M/12.7M [00:01&lt;00:03, 2.80MB/s]
 27%|‚ñà‚ñà‚ñã       | 3.38M/12.7M [00:01&lt;00:03, 2.84MB/s]
 30%|‚ñà‚ñà‚ñâ       | 3.75M/12.7M [00:01&lt;00:03, 2.86MB/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 4.12M/12.7M [00:01&lt;00:03, 2.90MB/s]
 35%|‚ñà‚ñà‚ñà‚ñå      | 4.50M/12.7M [00:01&lt;00:02, 3.02MB/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 4.88M/12.7M [00:02&lt;00:02, 2.90MB/s]
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5.25M/12.7M [00:02&lt;00:02, 2.93MB/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 5.62M/12.7M [00:02&lt;00:02, 2.91MB/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 6.00M/12.7M [00:02&lt;00:02, 2.85MB/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6.38M/12.7M [00:02&lt;00:02, 2.73MB/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 6.75M/12.7M [00:02&lt;00:02, 2.51MB/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 7.12M/12.7M [00:02&lt;00:02, 2.54MB/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 7.50M/12.7M [00:03&lt;00:02, 2.59MB/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 7.88M/12.7M [00:03&lt;00:01, 2.68MB/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 8.25M/12.7M [00:03&lt;00:01, 2.73MB/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 8.62M/12.7M [00:03&lt;00:01, 2.80MB/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 9.00M/12.7M [00:03&lt;00:01, 2.82MB/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 9.38M/12.7M [00:03&lt;00:01, 2.79MB/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 9.75M/12.7M [00:03&lt;00:01, 2.85MB/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 10.1M/12.7M [00:04&lt;00:00, 2.77MB/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10.5M/12.7M [00:04&lt;00:00, 2.71MB/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 10.9M/12.7M [00:04&lt;00:00, 2.58MB/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 11.2M/12.7M [00:04&lt;00:00, 2.57MB/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 11.6M/12.7M [00:04&lt;00:00, 2.56MB/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 12.0M/12.7M [00:04&lt;00:00, 2.53MB/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 12.2M/12.7M [00:04&lt;00:00, 2.53MB/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 12.5M/12.7M [00:05&lt;00:00, 2.47MB/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.7M/12.7M [00:05&lt;00:00, 2.59MB/s]
The model has 444867 trainable parameters
Train epoch 0: TotalLoss=0.143, PSNR=24.828
Eval epoch 0: PSNR=24.388
</pre></div>
</div>
<p>Test the trained model and plot the results:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">trainer</span><span class="o">.</span><span class="n">plot_images</span></a> <span class="o">=</span> <span class="kc">True</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_demo_gan_imaging_002.png" srcset="../../_images/sphx_glr_demo_gan_imaging_002.png" alt="Ground truth, Measurement, No learning, Reconstruction" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Eval epoch 0: PSNR=24.388, PSNR no learning=22.129
Test results:
PSNR no learning: 22.129 +- 2.703
PSNR: 24.388 +- 3.427

{&#39;PSNR no learning&#39;: np.float64(22.128802490234374), &#39;PSNR no learning_std&#39;: np.float64(2.703303237720839), &#39;PSNR&#39;: np.float64(24.388037109375), &#39;PSNR_std&#39;: np.float64(3.4268960671244293)}
</pre></div>
</div>
</section>
<section id="csgm-ambientgan-training">
<h2>CSGM / AmbientGAN training<a class="headerlink" href="#csgm-ambientgan-training" title="Link to this heading">ÔÉÅ</a></h2>
<p>Compressed Sensing using Generative Models (CSGM) and AmbientGAN are two methods for solving inverse problems
using generative models. CSGM (Bora et al., <a class="reference external" href="https://arxiv.org/abs/1703.03208">Compressed Sensing using Generative Models</a>) uses a generative model to solve the inverse problem by optimising the latent
space of the generator. AmbientGAN (Bora et al., <a class="reference external" href="https://openreview.net/forum?id=Hy7fDog0b">AmbientGAN: Generative models from lossy measurements</a>) uses a generative model to solve the inverse problem by optimising the
measurements themselves. Both methods are trained using an adversarial loss; the main difference is that CSGM requires
a ground truth dataset (supervised loss), while AmbientGAN does not (unsupervised loss).</p>
<p>In this example, we use a DCGAN as the
generator and discriminator, and train using the adversarial loss. The forward pass of the generator is given by:</p>
<p><strong>CSGM</strong> forward pass at train time:</p>
<div class="math notranslate nohighlight">
\[\hat x = \inverse{z},\quad z\sim \mathcal{N}(\mathbf{0},\mathbf{I}_k)\]</div>
<p><strong>CSGM</strong>/<strong>AmbientGAN</strong> forward pass at eval time:</p>
<div class="math notranslate nohighlight">
\[\hat x = \inverse{\hat z}\quad\text{s.t.}\quad\hat z=\operatorname*{argmin}_z \lVert \forw{\inverse{z}}-y\rVert _2^2\]</div>
<p><strong>CSGM</strong> loss:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}=\mathcal{L}_\text{adv}(\hat x, x;D)\]</div>
<p><strong>AmbientGAN</strong> loss (where <span class="math notranslate nohighlight">\(\forw{\cdot}\)</span> is the physics):</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}=\mathcal{L}_\text{adv}(\forw{\hat x}, y;D)\]</div>
<p>We next load the models and construct losses as defined above.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">G</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">CSGMGenerator</span></a><span class="p">(</span>
    <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">DCGANGenerator</span></a><span class="p">(</span><span class="n">output_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">nz</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">ngf</span><span class="o">=</span><span class="mi">32</span><span class="p">),</span> <span class="n">inf_tol</span><span class="o">=</span><span class="mf">1e-2</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">DCGANDiscriminator</span></a><span class="p">(</span><span class="n">ndf</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_models</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="o">=</span><span class="n">D</span><span class="p">,</span> <span class="n">lr_g</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">,</span> <span class="n">lr_d</span><span class="o">=</span><span class="mf">2e-4</span>
<span class="p">)</span>  <span class="c1"># learning rates from original paper</span>

<span class="c1"># For AmbientGAN:</span>
<span class="n">loss_g</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">adversarial</span><span class="o">.</span><span class="n">UnsupAdversarialGeneratorLoss</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>
<span class="n">loss_d</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">adversarial</span><span class="o">.</span><span class="n">UnsupAdversarialDiscriminatorLoss</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>

<span class="c1"># For CSGM:</span>
<span class="n">loss_g</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">adversarial</span><span class="o">.</span><span class="n">SupAdversarialGeneratorLoss</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>
<span class="n">loss_d</span> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">adversarial</span><span class="o">.</span><span class="n">SupAdversarialDiscriminatorLoss</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>
</pre></div>
</div>
<p>As before, we can now train our models. Since inference is very
slow for CSGM/AmbientGAN as it requires an optimisation, we only do one
evaluation at the end. Note the train PSNR is meaningless as this
generative model is trained on random latents.
Like above, we load a pretrained model trained in the exact same way for 50 epochs,
and fine-tune here for a quick demo with 1 epoch.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a> <span class="o">=</span> <a href="http://pytorch.org/docs/2.0/hub.html#torch.hub.load_state_dict_from_url" title="torch.hub.load_state_dict_from_url" class="sphx-glr-backref-module-torch-hub sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load_state_dict_from_url</span></a><span class="p">(</span>
    <span class="n">dinv</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_weights_url</span><span class="p">(</span><span class="s2">&quot;adversarial-demo&quot;</span><span class="p">,</span> <span class="s2">&quot;csgm_model.pth&quot;</span><span class="p">),</span>
    <span class="n">map_location</span><span class="o">=</span><span class="k">lambda</span> <span class="n">s</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">s</span><span class="p">,</span>
<span class="p">)</span>

<a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">G</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">])</span>
<a href="http://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">D</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;state_dict_D&quot;</span><span class="p">])</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">])</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">AdversarialTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">G</span><span class="p">,</span>
    <span class="n">D</span><span class="o">=</span><span class="n">D</span><span class="p">,</span>
    <span class="n">physics</span><span class="o">=</span><span class="n">physics</span><span class="p">,</span>
    <a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a><span class="o">=</span><a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">losses</span><span class="o">=</span><span class="n">loss_g</span><span class="p">,</span>
    <span class="n">losses_d</span><span class="o">=</span><span class="n">loss_d</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">save_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">,</span>
<span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://huggingface.co/deepinv/adversarial-demo/resolve/main/csgm_model.pth?download=true&quot; to /home/runner/.cache/torch/hub/checkpoints/csgm_model.pth

  0%|          | 0.00/49.3M [00:00&lt;?, ?B/s]
  1%|‚ñè         | 640k/49.3M [00:00&lt;00:09, 5.32MB/s]
  3%|‚ñé         | 1.25M/49.3M [00:00&lt;00:09, 5.20MB/s]
  4%|‚ñé         | 1.75M/49.3M [00:00&lt;00:09, 5.04MB/s]
  5%|‚ñç         | 2.25M/49.3M [00:00&lt;00:10, 4.79MB/s]
  6%|‚ñå         | 2.75M/49.3M [00:00&lt;00:10, 4.68MB/s]
  7%|‚ñã         | 3.25M/49.3M [00:00&lt;00:10, 4.73MB/s]
  8%|‚ñä         | 3.75M/49.3M [00:00&lt;00:10, 4.74MB/s]
  9%|‚ñä         | 4.25M/49.3M [00:00&lt;00:10, 4.53MB/s]
 10%|‚ñâ         | 4.75M/49.3M [00:01&lt;00:10, 4.60MB/s]
 11%|‚ñà         | 5.25M/49.3M [00:01&lt;00:10, 4.39MB/s]
 12%|‚ñà‚ñè        | 5.75M/49.3M [00:01&lt;00:10, 4.37MB/s]
 13%|‚ñà‚ñé        | 6.25M/49.3M [00:01&lt;00:10, 4.27MB/s]
 14%|‚ñà‚ñé        | 6.75M/49.3M [00:01&lt;00:10, 4.31MB/s]
 15%|‚ñà‚ñç        | 7.25M/49.3M [00:01&lt;00:10, 4.38MB/s]
 16%|‚ñà‚ñå        | 7.75M/49.3M [00:01&lt;00:10, 4.31MB/s]
 17%|‚ñà‚ñã        | 8.25M/49.3M [00:01&lt;00:10, 4.29MB/s]
 18%|‚ñà‚ñä        | 8.75M/49.3M [00:02&lt;00:09, 4.32MB/s]
 19%|‚ñà‚ñâ        | 9.25M/49.3M [00:02&lt;00:10, 4.10MB/s]
 20%|‚ñà‚ñâ        | 9.75M/49.3M [00:02&lt;00:10, 4.12MB/s]
 21%|‚ñà‚ñà        | 10.2M/49.3M [00:02&lt;00:09, 4.37MB/s]
 22%|‚ñà‚ñà‚ñè       | 10.8M/49.3M [00:02&lt;00:08, 4.54MB/s]
 23%|‚ñà‚ñà‚ñé       | 11.2M/49.3M [00:02&lt;00:08, 4.67MB/s]
 24%|‚ñà‚ñà‚ñç       | 11.8M/49.3M [00:02&lt;00:08, 4.64MB/s]
 25%|‚ñà‚ñà‚ñç       | 12.2M/49.3M [00:02&lt;00:08, 4.77MB/s]
 26%|‚ñà‚ñà‚ñå       | 12.8M/49.3M [00:02&lt;00:08, 4.73MB/s]
 27%|‚ñà‚ñà‚ñã       | 13.2M/49.3M [00:03&lt;00:08, 4.55MB/s]
 28%|‚ñà‚ñà‚ñä       | 13.8M/49.3M [00:03&lt;00:08, 4.45MB/s]
 29%|‚ñà‚ñà‚ñâ       | 14.2M/49.3M [00:03&lt;00:08, 4.34MB/s]
 30%|‚ñà‚ñà‚ñâ       | 14.8M/49.3M [00:03&lt;00:08, 4.28MB/s]
 31%|‚ñà‚ñà‚ñà       | 15.2M/49.3M [00:03&lt;00:08, 4.39MB/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 15.8M/49.3M [00:03&lt;00:07, 4.48MB/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 16.2M/49.3M [00:03&lt;00:07, 4.51MB/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 16.8M/49.3M [00:03&lt;00:07, 4.54MB/s]
 35%|‚ñà‚ñà‚ñà‚ñç      | 17.2M/49.3M [00:04&lt;00:07, 4.42MB/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 17.8M/49.3M [00:04&lt;00:07, 4.44MB/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 18.2M/49.3M [00:04&lt;00:07, 4.49MB/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 18.8M/49.3M [00:04&lt;00:07, 4.50MB/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 19.2M/49.3M [00:04&lt;00:06, 4.51MB/s]
 40%|‚ñà‚ñà‚ñà‚ñà      | 19.8M/49.3M [00:04&lt;00:06, 4.56MB/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 20.2M/49.3M [00:04&lt;00:06, 4.64MB/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 20.8M/49.3M [00:04&lt;00:06, 4.61MB/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 21.2M/49.3M [00:04&lt;00:06, 4.69MB/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 21.8M/49.3M [00:05&lt;00:06, 4.75MB/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 22.2M/49.3M [00:05&lt;00:06, 4.71MB/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 22.8M/49.3M [00:05&lt;00:05, 4.67MB/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 23.2M/49.3M [00:05&lt;00:05, 4.55MB/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 23.8M/49.3M [00:05&lt;00:06, 4.44MB/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 24.2M/49.3M [00:05&lt;00:06, 4.33MB/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 24.8M/49.3M [00:05&lt;00:05, 4.36MB/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25.2M/49.3M [00:05&lt;00:05, 4.35MB/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 25.8M/49.3M [00:05&lt;00:05, 4.42MB/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 26.2M/49.3M [00:06&lt;00:05, 4.31MB/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 26.8M/49.3M [00:06&lt;00:05, 4.25MB/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 27.2M/49.3M [00:06&lt;00:05, 4.28MB/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 27.8M/49.3M [00:06&lt;00:05, 4.05MB/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 28.2M/49.3M [00:06&lt;00:05, 4.09MB/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 28.8M/49.3M [00:06&lt;00:05, 4.05MB/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 29.2M/49.3M [00:06&lt;00:05, 3.99MB/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 29.8M/49.3M [00:07&lt;00:05, 3.91MB/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 30.2M/49.3M [00:07&lt;00:04, 4.03MB/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 30.8M/49.3M [00:07&lt;00:04, 4.07MB/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 31.2M/49.3M [00:07&lt;00:04, 4.21MB/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31.8M/49.3M [00:07&lt;00:04, 4.13MB/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 32.2M/49.3M [00:07&lt;00:04, 4.13MB/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 32.8M/49.3M [00:07&lt;00:04, 4.14MB/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 33.2M/49.3M [00:07&lt;00:04, 4.20MB/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 33.8M/49.3M [00:08&lt;00:03, 4.18MB/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 34.2M/49.3M [00:08&lt;00:03, 4.08MB/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 34.8M/49.3M [00:08&lt;00:03, 4.10MB/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 35.2M/49.3M [00:08&lt;00:03, 4.23MB/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 35.8M/49.3M [00:08&lt;00:03, 4.23MB/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 36.2M/49.3M [00:08&lt;00:03, 4.28MB/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 36.8M/49.3M [00:08&lt;00:03, 4.22MB/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 37.2M/49.3M [00:08&lt;00:02, 4.23MB/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 37.8M/49.3M [00:09&lt;00:02, 4.27MB/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 38.2M/49.3M [00:09&lt;00:02, 4.21MB/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 38.8M/49.3M [00:09&lt;00:02, 4.36MB/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 39.2M/49.3M [00:09&lt;00:02, 4.46MB/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 39.8M/49.3M [00:09&lt;00:02, 4.49MB/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 40.2M/49.3M [00:09&lt;00:02, 4.59MB/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 40.8M/49.3M [00:09&lt;00:01, 4.64MB/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 41.2M/49.3M [00:09&lt;00:01, 4.65MB/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 41.8M/49.3M [00:09&lt;00:01, 4.62MB/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 42.2M/49.3M [00:10&lt;00:01, 4.75MB/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 42.8M/49.3M [00:10&lt;00:01, 4.72MB/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 43.2M/49.3M [00:10&lt;00:01, 4.69MB/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 43.8M/49.3M [00:10&lt;00:01, 4.69MB/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 44.2M/49.3M [00:10&lt;00:01, 4.68MB/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 44.8M/49.3M [00:10&lt;00:01, 4.69MB/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 45.2M/49.3M [00:10&lt;00:00, 4.72MB/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 45.8M/49.3M [00:10&lt;00:00, 4.67MB/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 46.2M/49.3M [00:10&lt;00:00, 4.70MB/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 46.8M/49.3M [00:11&lt;00:00, 4.63MB/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 47.2M/49.3M [00:11&lt;00:00, 4.56MB/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 47.8M/49.3M [00:11&lt;00:00, 4.64MB/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 48.2M/49.3M [00:11&lt;00:00, 4.64MB/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 48.8M/49.3M [00:11&lt;00:00, 4.61MB/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 49.2M/49.3M [00:11&lt;00:00, 4.62MB/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49.3M/49.3M [00:11&lt;00:00, 4.44MB/s]
The model has 3608000 trainable parameters
Train epoch 0: TotalLoss=0.007, PSNR=9.163
</pre></div>
</div>
<p>Eventually, we run evaluation of the generative model by running test-time optimisation
using test measurements. Note that we do not get great results as CSGM /
AmbientGAN relies on large datasets of diverse samples, and we run the
optimisation to a relatively high tolerance for speed. Improve the results by
running the optimisation for longer.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><a href="http://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Eval epoch 0: PSNR=9.528, PSNR no learning=22.129
Test results:
PSNR no learning: 22.129 +- 2.703
PSNR: 9.528 +- 1.301

{&#39;PSNR no learning&#39;: np.float64(22.128802490234374), &#39;PSNR no learning_std&#39;: np.float64(2.703303237720839), &#39;PSNR&#39;: np.float64(9.527952575683594), &#39;PSNR_std&#39;: np.float64(1.301279076545696)}
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (1 minutes 41.825 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-adversarial-learning-demo-gan-imaging-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/2f3e20ed263cc3e5c7e770603c2bda28/demo_gan_imaging.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">demo_gan_imaging.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/1b08a6c94b052657775204a9369c2c98/demo_gan_imaging.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">demo_gan_imaging.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/74982483541b96cb559b9926a0156344/demo_gan_imaging.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">demo_gan_imaging.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../advanced/demo_ri_basic.html" class="btn btn-neutral float-left" title="Radio interferometric imaging with deepinverse" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../basics/demo_lidar.html" class="btn btn-neutral float-right" title="Single photon lidar operator for depth ranging." accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, DeepInv.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEKFKYSGR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NSEKFKYSGR', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>